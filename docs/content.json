{"posts":[{"title":"gmp","text":"第一点gmp每个协程有独立的任务队列，线程池只维护了一个全局的任务队列，高并发情况下同步开销大，这里gmp体现的也是一个本地和全局的思想 第二点线程池其实是一种GM模型，这个模型缺点蛮多的，gmp引入了一个p，实际实现了计算存储分离 第三点线程池实际是一种资源池，是对一定规模的资源复用，gmp没有这个限制 第四点就是粒度和并发度,线程池的粒度是线程，gmp的粒度是协程，线程池的并发度是线程数，gmp的并发度是协程数,线程池的粒度和并发度是一致的，gmp的粒度和并发度是不一致的,这里gmp体现的是一个粗粒度和细粒度的思想,这里的粗粒度和细粒度是相对的 其实gmp体现的思想就是中间件的思想,遇到问题，就往中间加一层","link":"/posts/328f6061.html"},{"title":"TCP和Udp的区别是什么？","text":"一张图看懂TCP与UDP的区别，秒懂！ 哈哈，上面的图，大家看个乐就好，接下来，我从 7 个方面说说 TCP 和 UDP 区别。 1. 连接 TCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。 2. 服务对象 TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 3. 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。 4. 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 5. 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 6. 传输方式 TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 7. 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。 TCP 和 UDP 应用场景： 由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于： FTP 文件传输； HTTP / HTTPS； 由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于： 包总量较少的通信，如 DNS 、SNMP 等； 视频、音频等多媒体通信； 广播通信； 更多图解网络文章 网络基础篇 TCP/IP 网络模型有哪几层？ 键入网址到网页显示，期间发生了什么？ Linux 系统是如何收发网络包的？ HTTP 篇 HTTP 常见面试题 HTTP/1.1如何优化？ HTTPS RSA 握手解析 HTTPS ECDHE 握手解析 HTTPS 如何优化？ HTTP/2 牛逼在哪？ HTTP/3 强势来袭 既然有 HTTP 协议，为什么还要有 RPC？ TCP 篇 TCP 三次握手与四次挥手面试题 TCP 重传、滑动窗口、流量控制、拥塞控制 TCP 实战抓包分析 TCP 半连接队列和全连接队列 如何优化 TCP? 如何理解是 TCP 面向字节流协议？ 为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？ SYN 报文什么时候情况下会被丢弃？ 四次挥手中收到乱序的 FIN 包会如何处理？ 在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？ TCP 连接，一端断电和进程崩溃有什么区别？ 拔掉网线后， 原本的 TCP 连接还存在吗？ tcp_tw_reuse 为什么默认是关闭的？ HTTPS 中 TLS 和 TCP 能同时握手吗？ TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？ TCP 有什么缺陷？ 如何基于 UDP 协议实现可靠传输？ TCP 和 UDP 可以使用同一个端口吗？ 服务端没有 listen，客户端发起连接建立，会发生什么？ 没有 accpet，可以建立 TCP 连接吗？ 用了 TCP 协议，数据一定不会丢吗？ IP 篇 IP 基础知识全家桶 ping 的工作原理 学习心得 计算机网络怎么学？ 画图经验分享","link":"/posts/849b1d99.html"},{"title":"博客发烧党｜关于如何更好的进行知识分享的思考——附带 Hexo+Icarus 主题配置文件","text":"如果您看到这篇文章,表示您的 blog 已经安装成功. 在 Hexo 中，你可以通过设置文章的 front-matter（文章头部的配置信息）来实现置顶文章。具体步骤如下： 打开需要置顶的文章，找到 front-matter 部分； 在 front-matter 中添加 sticky: true，表示该文章需要置顶； 如果你想让多篇文章按照一定的顺序置顶，可以在 sticky 属性后面再添加一个数字，数字越小，文章的权重越高，例如 sticky: 1； 保存文章，重新生成网站即可看到效果。需要注意的是，如果你的主题没有对置顶文章做出特殊的处理，那么置顶文章会直接显示在文章列表的最上面。如果你想要更加精细的控制，可以在主题的模板文件中添加一些逻辑判断来实现。不需要插件，Hexo 默认就支持置顶文章功能。你只需要在文章的 front-matter 中添加 sticky: true 属性即可将该文章置顶。如果你想要多篇文章按照一定的顺序置顶，可以在 sticky 属性后面再添加一个数字，数字越小，文章的权重越高，例如 sticky: 1。 markdown语法提供了很多页面标签，但对于一个网站来说还是太少了，所有你在markdown语法中找不到的标签都可以在Hexo文档中找到，在Hexo中找不到的都可以在Icarus文档和iMaeGoo中找到，在Icarus中找不到的都可以在Bluma文档中找到(Icarus使用的Bluma插件库) 这是html的写法，我个人认为还存在markdown的写法，等日后研究hexo文档再做更新，暂时就这样吧。我不是很建议在文章中使用这些不方便移植的写法，这会导致主题在迁移的时候文章样式变得很难迁移。 文章内容有误？请点击 此处提交修改。 本文同时提供以下语言的翻译：English。 1234567891011121314{% tabs align:fullwidth size:small style:toggle-rounded %}&lt;!-- tab id:tab1 &quot;icon:fa-brands fa-github&quot; title:tab1 active --&gt;tab1&lt;!-- endtab --&gt;&lt;!-- tab id:tab2 &quot;icon:fa-brands fa-node-js&quot; title:tab2 --&gt;tab2&lt;!-- endtab --&gt;&lt;!-- tab id:tab3 &quot;icon:fa-brands fa-qq&quot; title:tab3 --&gt;tab3&lt;!-- endtab --&gt;&lt;!-- tab id:tab4 &quot;icon:fa-brands fa-weixin&quot; title:tab4 --&gt;tab4&lt;!-- endtab --&gt;{% endtabs %} 更新手法1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d tab 标签语法 ： 123456789101112131415161718{% tabs [Unique name], [index] %} &lt;!-- tab [Tab caption]@[icon] --&gt; 标签页内容（支持行内标签） &lt;!-- endtab --&gt;{% endtabs %}{% tabs Tab标签列表 %} &lt;!-- tab 标签页1 --&gt; 标签页1文本内容 &lt;!-- endtab --&gt; &lt;!-- tab 标签页2 --&gt; 标签页2文本内容 &lt;!-- endtab --&gt; &lt;!-- tab 标签页3 --&gt; 标签页3文本内容 &lt;!-- endtab --&gt;{% endtabs %} 其中，各参数意义如下： Unique name: 全局唯一的 Tab 名称，将作为各个标签页的 id 属性前缀 index: 当前激活的标签页索引，如果未定义则默认选中显示第一个标签页，如果设为 - 1 则默认隐藏所有标签页 Tab caption: 当前标签页的标题，如果不指定则会以 Unique name 加上索引作为标题 icon: 在标签页标题中添加 Font awesome 图标 Hexo+Icarus 主题配置文件hexo+icarlus >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172title: 未来可妻subtitle: ''description: ''keywords: nullauthor: JIeJaittlanguage: zh-CNtimezone: ''url: https://jiejaitt.github.ioroot: /#permalink: ':year/:month/:day/:title/'# permalink_defaults: nullpermalink: posts/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hexpretty_urls: trailing_index: true trailing_html: truesource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: ':lang'skip_render: nullnew_post_name: ':title.md'default_layout: posttitlecase: falseexternal_link: enable: true field: site exclude: ''filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: '' wrap: true hljs: falseprismjs: enable: false preprocess: true line_number: true tab_replace: ''index_generator: path: '' per_page: 10 order_by: '-date'default_category: uncategorizedcategory_map: nulltag_map: nullmeta_generator: truedate_format: YYYY-MM-DDtime_format: HH:mm:ssupdated_option: mtimeper_page: 10pagination_dir: pageinclude: nullexclude: nullignore: nulltheme: icarusdeploy: type: git repo: git@github.com:JIeJaitt/jiejaitt.github.io.git branch: main _config.yml >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374title: 未来可妻subtitle: ''description: ''keywords: nullauthor: JIeJaittlanguage: zh-CNtimezone: ''url: https://jiejaitt.github.ioroot: /#permalink: ':year/:month/:day/:title/'# permalink_defaults: nullpermalink: posts/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hexpretty_urls: trailing_index: true trailing_html: truesource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: ':lang'skip_render: nullnew_post_name: ':title.md'default_layout: posttitlecase: falseexternal_link: enable: true field: site exclude: ''filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: '' wrap: true hljs: falseprismjs: enable: false preprocess: true line_number: true tab_replace: ''index_generator: path: '' per_page: 10 order_by: '-date'default_category: uncategorizedcategory_map: nulltag_map: nullmeta_generator: truedate_format: YYYY-MM-DDtime_format: HH:mm:ssupdated_option: mtimeper_page: 10pagination_dir: pageinclude: nullexclude: nullignore: nulltheme: icarusdeploy: type: git repo: git@github.com:JIeJaitt/jiejaitt.github.io.git branch: main 优化Hexo博客文章永久链接文章默认的URL配置是包含年月日以及文章标题的，而且每次文章文章有修改就会引起一些链接的变化，繁琐且不易于检索传播。而URL地址对于SEO来说（Search Engine Optimization：搜索引擎优化）是相当重要的，如何缩短并固定每篇文章的连接，同时又可以在链接后面加上html使其显得更为正式。 基于Hexo搭建的博客，可以通过插件hexo-abbrlink来实现自定义文章的连接。首先我们使用如下代码进行优化： 1npm install hexo-abbrlink --save 接着打开站点配置文件_config.yml，按照如下部分进行相关配置： 12345678910# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: https://jiejaitt.github.ioroot: /#permalink: :year/:month/:day/:title/#permalink_defaults:permalink: posts/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 如上所示，是我本人的配置，另，permalink的配置，我多加了一个固定链接posts，纯属个人喜好，你也可以去掉直接配置成:abbrlink.html。我们完成了如上的配置后，如果不对博客文章做任何处理的话，在部署的时候，将会根据算法随机生成每篇博客的数字链接。当然，如果你觉得使用随机的数字连接不具有识别性，想要自定义每篇博客的链接的话也是可以的，只需要在你的博客.md文章的头部配置如下字段即可： 1abbrlink: your_blog_url 通过这一顿操作，你就可以随心所欲控制你的博客的链接了。每次修改博客文章的时候，只要不修改abbrlink配置项，那么这篇博客的链接就永远不会发生变化。这样不仅有利于博客链接的记忆与传播，更有利于整个博客的SEO优化，提升检索度和排名。 官方文章中你还可以使用如下变量的配置，当然除了这些还可以使用Front-matter中的所有属性。 变量 描述 :year 文章的发表年份（4 位数） :month 文章的发表月份（2 位数） :i_month 文章的发表月份（去掉开头的零） :day 文章的发表日期 (2 位数) :i_day 文章的发表日期（去掉开头的零） :hour 文章发表时的小时 (2 位数) :minute 文章发表时的分钟 (2 位数) :second 文章发表时的秒钟 (2 位数) :title 文件名称 (relative to “source/_posts/“ folder) :name 文件名称 :post_title 文章标题 :id 文章 ID (not persistent across cache reset) :category 分类。如果文章没有分类，则是 default_category 配置信息。 :hash 文件名（与 :title 相同）和日期（12-16进制）的 SHA1 哈希值 您可在 permalink_defaults 参数下调整永久链接中各变量的默认值： 12permalink_defaults: lang: en 示例如下： source/_posts/lorem/hello-world.md >unfolded12345title: Hello Worlddate: 2013-07-14 17:01:34categories:- foo- bar 参数 结果 :year/:month/:day/:title/ 2013/07/14/lorem/hello-world/ :year/:month/:day/:name/ 2013/07/14/hello-world/ 若要建立一个多语种的网站，您可修改 new_post_name 和 permalink 参数，如下： 12new_post_name: :lang/:title.mdpermalink: :lang/:title/ 当您建立新文章时，文章会被储存到： 12$ hexo new &quot;Hello World&quot; --lang tw# =&gt; source/_posts/tw/Hello-World.md 而网址会是： 1http://localhost:4000/tw/hello-world/ Cloud workSpace Notion-Like GitHub-Like netdisc list Notion ClickUp Craft 语雀 Evernote Github Gitee 百度网盘 阿里网盘 TickTick Frequent bloggers 博主 主页链接 其他 PPOffice PPOffice / 辣椒の酱 辣椒の酱 / iMaeGoo iMaeGoo / Yida Yida / Xinyu Liu Xinyu Liu / Yida Yida / 李文周 李文周 / Future plan 把博客的评论区搬到搬迁合并为一个仓库 完善收集一些优化文章样式特殊的语法 https://whatsid.me/2019/08/21/hexo-markdown-syntax/# 加密某些重要内容的文章","link":"/posts/44948533.html"},{"title":"操作系统2023年2月春季期末考试复习资料","text":"从用户观点看，UNIX系统将文件分三类：普通文件、目录文件和索引文件。 访问临界资源应遵循的准则是：空闲让进、忙则等待、有限等待、让权等待。 传统操作系统提供的第一代用户界面接口是命令行 和系统调用。 进程是一个程序对某个数据集的一次运行活动。 操作系统的五大管理功能是处理机管理、储存器管理、设备管理、作业管理和用户接口 。 进程的并发执行是指若干进程在执行时间上是重叠的。 某系统中有3个并发的进程，都需要同类资源4个，该系统中不会因这类资源发生死锁的最少资源数目是10个。 解释：当有三个并发进程同时对资源进行申请时，最可能发生死锁的情况是三个进程当前各自都占据了3个资源，此时，只再需要1个该类资源，即可以在这种情况下不发生死锁。 并发进程在访问共享变量时，可能会出现与时间 有关的错误。 虚拟存储器管理系统的基础是程序的局部性原理。 重定位是指由于一个作业装入到与其地址空间不一致的存储空间所引起的对有关地址部分的调整过程。 进程存在的唯一标志是进程控制块。 产生死锁的四个必要条件是：互斥使用条件、不剥夺条件、请求与保持条件、环路等待条件。 (重点)什么是操作系统？它有什么基本特征？ 操作系统是一组控制和管理计算机硬件和软件资源，合理地对各类作业进行调度，以及方便用户使用的程序的集合。 基本特征是并发、共享、虚拟和异步并发：指两个或多个事件在同一时间间隔内发生共享：指系统中的资源可供内存中多个并发执行的进程共同使用虚拟：指把一个物理上的实体变为若干个逻辑上的对应物异步：由于资源有限，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性 分时系统的响应时间受哪些因素的影响？ 时间片长度 终端用户个数 命令本身功能 硬件特性 主存与辅存的交换速度 什么是处理机现场信息？ 处理机现场信息是处理机在任意时刻的状态信息集合，主要包括处理机程序状态寄存器的值、程序计数器和各个寄存器的值。 (重点)进程和线程的主要区别是什么？ 在有进程和线程的系统中，进程是系统资源分配的独立单位，而线程是可调度运行的独立单位。 多道程序系统如何实现CPU计算与I/O操作的并行？ 在多道程序系统中，当需要I/O操作时，不需要CPU直接控制I/O操作的完成。可利用通道、DMA及中断机构来直接控制I/O操作的完成这时CPU也不是专门空闲等待I/O操作的完成，而是转去执行另一道程序。 (重点)引起进程调度的主要因素有： 一个进程运行完毕。 一个正在运行的进程被阻塞。 在抢占式调度中，一个高优先级的进程被创建。 在抢占式调度中，一个高优先级的进程由阻塞被唤醒。 在轮转式调度中，正垢进程运行完一个时间片。 操作系统对计算机系统性能的影响有哪些？ 操作系统会影响到计算机系统的可靠性、方便性、效率、可维护性、处理任务的速度、软件成本等。 (重点)CPU在管态和目态下工作有何不同？ 处于管态时，可以执行包括特权指令在内的一切面器指令,而在目态下工作时不允许执行特权指令。 (重点)什么是动态链接？用何种内存分配方法可以实现这种链接？ 动态链接就是指程序运行到需要调度某一模块的时候再去链接,对于未使用的模块就可以不必链接。 采用段式内存分配方法可以实现这种动态链接。 (非重点，以24题的形式考察)什么是内存的有效存取时间。 内存的有效存取时间（EAT）也称为平均存取时间（AAT），是衡量计算机内存性能的指标之一。它表示从发出内存读/写请求到获取所需数据的平均时间，包括了寻址、传输、存储器的访问等多个阶段的时间。一般来说，内存的EAT越小，说明计算机内存性能越好，读写数据的速度越快。 (重点)考虑一个有快表的请求分页系统，设内存的读写周期为 1ns，内外存之间传送一个页面的平均时间为 5000ns，快表的命中率为 80%，页面失效率为 10%，求内存的有效存取时间。 命中快表：80% * 1ns = 0.8 ns;（假设访问快表为0ns）未命中快表：20% * (1ns + {});{} 内又分缺页和：10% * (5000ns+1ns) 与不缺页：90% * (1ns) EAT = 80% * 1ns + 20% * (1ns + {10% * (5000ns+1ns) + 90% * (1ns) }) = 101.2 ns","link":"/posts/88cf822b.html"},{"title":"置顶","text":"几个需要解决的问题Go语言项目提示变量 ‘sql’ 与导入的软件包名称冲突这意味着你同时使用了一个标识符sql的包(比如database/sql)和一个本地定义的sql变量/常量。Go语言不允许重用标识符。所以你必须选择: 重命名一个sql,不再冲突: 123import &quot;database/sql&quot;localSql := &quot;some other name&quot; 完全重新命名包引用,以避免冲突: 1234import dbsql &quot;database/sql&quot;sql := &quot;local definition&quot; 删除其中一个sql,取决于它是最重要的: 1234import &quot;database/sql&quot;someOtherName := &quot;local definition&quot; 总的来说,这里有几种解决方法: 重命名本地标识符(sql变为localSql)重命名引入的包(dbsql替代database/sql)删除本地标识符删除引入的包 选择其中一种,以解决冲突并使你的代码有效。 希望这个解释有助于你!请在有任何其他问题时再问。 请问协程间通信方式有哪些协程间通信主要有以下几种方式: 信号量(Semaphore)用来控制可以同时进入临界区的最大线程数,以确保资源的安全使用。 管道(Channel)用于 actors 之间安全共享消息的彻底解决方案。通常用来处理异步通信。 共享内存(Shared Memory)多个协程可以直接访问和修改共同的内存块来共享数据。但需要额外加锁来防止并发修改导致的问题。 信号(Signal)用于通知其他协程某个事件发生了,却不会阻塞发送端或者接收端的协程。非常轻量级。 队列(Queue)用于保存和管理多个消息的先进先出集合。协程可以通过生产者-消费者模式来共享队列。 事件(Event)表示某个状态的抽象对象,可以被多个协程监听。当事件状态发生变化时,会通知所有监听者。 数据库是比较稳定和常用的共享内存形式。多个协程可以通过事务等机制共同访问并修改数据库来完成通信。 除此之外,还有消息队列(Message Queue)、消息中间件(Message Middleware) 这两种方式。它们都是基于异步消息通信的高级概念。 总的来说,主要的协程通信方式包括: 同步通信:共享内存、信号量异步通信:管道、消息队列、事件轻量级通信:信号 不同的方式适用于不同的场景,要合理选择以确保高效、安全、低耦合。阻塞与非阻塞也需要权衡, marrying 多种方式也是常见选择。 怎么给自己的项目测qps？测量项目的QPS(每秒查询数量)有几种方法: 使用压力测试工具,像压力搭船团队常用的Apache Bench (ab)工具。这个工具可以以命令行的方式发出指定数量的请求,并报告QPS结果。 例如,要发出100000次请求,命令如下:ab -n 100000 http://your-server-url/它会报告类似如下结果:This is ApacheBench, Version 2.3 &lt;$Revision: 1430 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking your-server-url (be patient)Completed 100000 requestsCompleted 100000 requestsFinished 100000 requestsTime taken: 19.0909 secondsServer Software:Server Hostname: your-server-hostServer Port: 8080 Document Path: /Document Length: 7312 bytes Concurrency Level: 100Time taken for tests: 19.0909 secondsComplete requests: 100000Failed requests: 0Write errors: 0Total transferred: 731200000 bytesHTML transferred: 730400000 bytesRequests per second: 5254.12 [#/sec] (mean)Time per request: 190.909 [ms] (mean)Time per request: 1.909 [ms] (mean, across all concurrent requests)Transfer rate: 3815.83 [Kbytes/sec] received Connection Times (ms)min mean[+/-sd] median maxConnect: 12 12 0.2 12 14Processing: 165 190 22.4 192 310Waiting: 164 189 22.3 191 308Total: 177 202 22.5 204 324 Percentage of the requests served within a certain time (ms)50% 20266% 20875% 21480% 22090% 23695% 24898% 25699% 280100% 324 (longest request) 使用任何语言的QPS库,像Python的汤姆棱有 requests-raspberrypi 包,用C的有 wrk 工具 等等。这些都可以简单、容易地发出大量 HTTP 请求并报告QPS结果。 使用网站流量监控工具。像Awstats, Google Analytics 等可以不断记录网站访问量,根据一段时间内的总访问量和时间长度计算出平均QPS。这个方法更加实际,但需要部署监控工具。 当负载测试使用mock服务器时,可以直接在mock服务器上查询访问记录,计算QPS。这种方法最精确,但也最复杂,需要设置好mock环境。 总之,选择一种适合你项目需求和技能的方法来测量QPS是非常合理的。 希望这些建议能帮助到你! Go语言有很多用于测量QPS(每秒查询数量)的第三方库。 其中较为常见的有: wrk - 轻量级的HTTP性能测试工具。可以用于测量QPS、带宽、 latencies 等。使用很简单,像下面这样:wrk -t2 -c100 -d30s http://example.com/这会发出100个并发请求,总计持续30秒,测得QPS和其他指标。 hey - 简单易用的HTTP/HTTPS性能测试工具。也支持QPS、latencies 等测量。使用方法类似wrk。 Load - 高度可定制的负载测试工具。可以生成各种负载模式的请求并报告QPS。比较灵活,用法较复杂。 fasthttp-tester - 提供简单的请求计数器,可以发出重载测试所需的所有类型请求。也支持QPS计算。 go-http-client/auto - 自动化的HTTP客户端,支持各种负载模式的QPS测试。包含detailed错误报告功能。 vegeta - 高性能的HTTP负载测试工具,特点是可靠性高、准确性强。用于C10K级别的QPS测试。使用Go语言编写。 k6 - 现代、用户友好的开源负载测试和性能监测工具。支持 HTTP/HTTPS 各种 load 协议,QPS 等各种指标测量。 除了这些专门用于QPS测量的工具外,你也可以使用标准的HTTP客户端(如net/http)在项目中手写QPS测试代码。不过使用现成的工具会更简单高效。 总体来说,Go语言是非常适合进行QPS测试的语言,提供了足够丰富的工具资源。你可以选择其中一种或多种工具来完善项目的性能测试功能。 手写QPS(每秒查询数量)测试代码主要需要以下几步: 初始化HTTP客户端。使用net/http包中的Client。例如:client := &amp;http.Client{} 实例化请求。使用http.Request。需要设置请求方法(如GET)、请求URL等。例如:req, _ := http.NewRequest(“GET”, “http://example.com/&quot;, nil) 发出请求并获得响应。使用Client.Do()发出请求,获得*http.Response对象。例如:resp, _ := client.Do(req)defer resp.Body.Close() 记录请求响应时间。使用time包获取开始和结束时间,计算请求耗时。例如:start := time.Now()// 发出请求和获得响应end := time.Now()cost := end.Sub(start) 累加请求数量和总耗时。在测试周期内,不断累加请求数量和各请求耗时,以求出平均QPS。例如:requests++totalCost += cost.Seconds() 计算QPS。在测试结束后,通过总耗时和请求数量计算平均QPS。QPS = float64(requests) / totalCost 结果输出及分析。输出平均QPS及其它需要统计的数据,对性能结果进行分析。 具体的代码示例如下:client := &amp;http.Client{} requests := 0totalCost := 0for i := 0; i &lt; 100000; i++ {req, _ := http.NewRequest(“GET”, “https://example.com/&quot;, nil)start := time.Now()resp, _ := client.Do(req)defer resp.Body.Close()end := time.Now()cost := end.Sub(start)requests++totalCost += cost.Seconds()} QPS := float64(requests) / totalCostfmt.Println(“QPS:”, QPS)// 其他统计和分析… 除了以上步骤,你还需要考虑并发数、测试时间间隔、输出结果等细节,以获得更准确、可靠的QPS测试结果。但总体来说,手写QPS测试代码就是按以上步骤进行请求发出、耗时统计和QPS计算,再给出详细分析报告。","link":"/posts/cc4d5834.html"},{"title":"sql｜Structured Query Language","text":"Character Set：utf8mb3 什么是窗口函数？窗口函数是一种SQL函数，它允许我们在执行聚合操作（如 SUM、AVG、MAX、MIN 等）时，按照特定的窗口（也称为分组）进行操作，以便在结果中包含更多的列和信息。 在使用传统的聚合函数进行查询时，结果只包含聚合后的值。例如，如果我们要查询某个表中的每个类别的总销售额，那么传统的查询将只返回总销售额。但是，在实际应用中，我们可能还需要在结果集中包含其他信息，例如每个类别的销售额排名、销售额占比等等。这时就可以使用窗口函数。 窗口函数可以用来计算与当前行相关的聚合值，而不是对整个结果集执行聚合操作。它们允许我们将一个大的结果集分成更小的分组，并对每个分组执行聚合操作，同时仍然可以在结果中返回每个分组的详细信息。 窗口函数在使用时，通常需要指定 OVER 子句来定义窗口的范围和排序方式。窗口可以按照一些列进行排序，然后根据这些排序后的列的值来计算聚合值。例如，我们可以使用窗口函数来计算某个员工的平均薪资，而不仅仅是整个公司的平均薪资。 常见的窗口函数包括 RANK、ROW_NUMBER、DENSE_RANK、NTILE、LEAD、LAG、SUM、AVG、MAX、MIN 等。 窗口函数和聚合函数有一些相似之处，但它们是不同的。聚合函数计算一组数据的总和、平均值、最大值、最小值等等，返回一个单一的汇总结果，而且通常用于 GROUP BY 语句中。窗口函数在处理数据时可以类似于聚合函数，但它们不会合并行并返回单一结果。相反，它们将结果返回到每个行中，并与其他行的结果进行比较。窗口函数不会修改原始数据集，而是返回一个新的数据集。因此，虽然窗口函数和聚合函数都可以用于对数据进行计算和处理，但它们的结果集不同，窗口函数可以提供更多的灵活性和控制，通常在需要对行级数据进行计算和处理的情况下使用。 以下是一些窗口函数的实际使用示例： 使用 RANK() 函数来计算销售额排名 123456SELECT product_name, sales_amount, RANK() OVER (ORDER BY sales_amount DESC) AS sales_rankFROM sales 使用 ROW_NUMBER() 函数来为每个分组分配序号 1234567SELECT customer_id, order_date, order_amount, ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date ASC) AS order_numFROM orders 使用 NTILE() 函数将行分组到 n 个组中 123456SELECT customer_name, order_amount, NTILE(4) OVER (ORDER BY order_amount DESC) AS quartileFROM orders 使用 SUM() 函数来计算移动平均值 123456SELECT date, sales_amount, SUM(sales_amount) OVER (ORDER BY date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS moving_averageFROM sales 使用 LEAD() 和 LAG() 函数来比较当前行与前一行或后一行的值 1234567SELECT date, sales_amount, LEAD(sales_amount, 1) OVER (ORDER BY date) AS next_day_sales, LAG(sales_amount, 1) OVER (ORDER BY date) AS previous_day_salesFROM sales 这些示例只是窗口函数的一部分用例，实际上，窗口函数可以用于许多其他用途，例如计算百分比、累计求和、行间差异、数据填充等等。 寻找今年具有正收入的客户123456789101112131415161718192021222324252627282930313233CREATE TABLE IF NOT EXISTS Customers ( customer_id INT, year INT, revenue INT);TRUNCATE TABLE Customers;INSERT INTO Customers (customer_id, year, revenue)VALUES ('1', '2018', '50');INSERT INTO Customers (customer_id, year, revenue)VALUES ('1', '2021', '30');INSERT INTO Customers (customer_id, year, revenue)VALUES ('1', '2020', '70');INSERT INTO Customers (customer_id, year, revenue)VALUES ('2', '2021', '-50');INSERT INTO Customers (customer_id, year, revenue)VALUES ('3', '2018', '10');INSERT INTO Customers (customer_id, year, revenue)VALUES ('3', '2016', '50');INSERT INTO Customers (customer_id, year, revenue)VALUES ('4', '2021', '20');SELECT customer_id AS 'customer_id'FROM CustomersWHERE year = 2021 AND revenue &gt; 0; 表：Customers 12345678910+--------------+------+| Column Name | Type |+--------------+------+| customer_id | int || year | int || revenue | int |+--------------+------+(customer_id, year) 是这个表的主键。这个表包含客户 ID 和不同年份的客户收入。注意，这个收入可能是负数。 写一个 SQL 查询来查询 2021 年具有 正收入 的客户。 可以按 任意顺序 返回结果表。 查询结果格式如下例。 12345678910111213141516171819202122232425Customers+-------------+------+---------+| customer_id | year | revenue |+-------------+------+---------+| 1 | 2018 | 50 || 1 | 2021 | 30 || 1 | 2020 | 70 || 2 | 2021 | -50 || 3 | 2018 | 10 || 3 | 2016 | 50 || 4 | 2021 | 20 |+-------------+------+---------+Result table:+-------------+| customer_id |+-------------+| 1 || 4 |+-------------+客户 1 在 2021 年的收入等于 30 。客户 2 在 2021 年的收入等于 -50 。客户 3 在 2021 年没有收入。客户 4 在 2021 年的收入等于 20 。因此，只有客户 1 和 4 在 2021 年有正收入。 从不订购的客户123456select customers.name as 'Customers'from customerswhere customers.id not in( select customerid from orders);","link":"/posts/572661ae.html"},{"title":"二分查找","text":"买卖股票的最佳时机：https://leetcode.cn/problems/best-time-to-buy-and-sell-stock/ 买卖股票的最佳时机 II：https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/ 寻找峰值：https://leetcode.cn/problems/find-peak-element/description/ 不需要考虑mid+1、mid-1的二分查找模板，希望大家都能学会：https://blog.csdn.net/WJPnb1/article/details/126360962?spm=1001.2014.3001.5502","link":"/posts/binary-search.html"},{"title":"LRU缓存机制","text":"CodeTopproblems146. LRU 缓存","link":"/posts/9daba997.html"},{"title":"数字信号处理2023年2月春季期末考试复习资料","text":"一线性时不变系统，输入为 x（n）时，输出为 y（n） ；则输入为 2x（n）时，输出为 2y（n） ；输入为 x（n-3）时，输出为 y（n-3） 。 解答：一线性时不变系统的性质是线性和时不变，所以输入为 2x(n) 时，输出为 2y(n)。输入为 x(n-3) 时，输出为 y(n-3)。 从奈奎斯特采样定理得出，要使实信号采样后能够不失真还原，采样频率 fs 与信号最高频率 fmax 关系为：fs &gt; 2fmax 。 解答：奈奎斯特采样定理是数字信号处理的基础，它指出了一个信号的最高频率不能超过采样频率的一半，否则将会发生丢失信息，称为“采样丢失”。因此，为了保证实信号在采样后能够不失真还原，采样频率必须大于信号的最高频率的两倍。 已知一个长度为 N 的序列 x(n)，它的离散时间傅立叶变换为 $X(e^{jw})$，它的 N 点离散傅立叶变换 X（K）是关于 $X(e^{jw})$ 的 N 点等间隔 采样 。 解答：N 点 离散傅立叶变换 (DFT) 是在 N 个等间隔的离散点上进行傅立叶变换的结果。DFT 的点等间隔与时间序列采样率和时间长度有关。 有限长序列 x(n)的 8 点 DFT 为 X（K），则 X（K）= 答案。 用脉冲响应不变法进行 IIR 数字滤波器的设计，它的主要缺点是频谱的泄露 所产生的 不稳定现象。 δ(n)的 z 变换是 1。 用窗函数法设计 FIR 数字滤波器时，加矩形窗比加三角窗时，所设计出的滤波器的过渡带比较 宽 ，阻带衰减比较 弱。 用双线性变法进行 IIR 数字滤波器的设计，从 s 平面向 z 平面转换的关系为 s= (1-1/z)/T。 解答： 若正弦序列 x(n)=sin(30nπ/120)是周期的,则周期是 N= 8。 解答：因为周期是指在一段时间内函数回到原始状态的时间，那么正弦函数的周期是 2π。对于给定的正弦序列 x(n)=sin(30nπ/120)，可以看到它的周期被缩放了 30/120=1/4。因此，该正弦序列的周期 N = (2π) / (1/4) = 8。 序列 x1（n）的长度为 4，序列 x2（n）的长度为 3，则它们线性卷积的长度是6 ，5 点圆周卷积的长度是5 。 线性卷积的长度是序列 x1 的长度加上序列 x2 的长度减 1，这是因为每一次卷积计算都会使原始序列向左或向右移动一个单位长度，所以线性卷积的长度为长度较长的序列长度加上长度较短的序列长度减 1。 对于 5 点圆周卷积，这个长度是 N 的最小正整数，使得 N 大于等于两个序列的长度，这样每一次卷积计算都是基于整个圆周长度，从而可以保证卷积结果是正确的。因此，5 点圆周卷积的长度就是 N。 DFT 与 DFS 有密切关系，因为有限长序列可以看成周期序列的若干倍的周期性扩展 ，而周期序列可以看成有限长序列的重复周期重构。 对长度为 N 的序列 x(n)圆周移位 m 位得到的序列用 $x_m(n)$表示，其数学表达式为 $x_m(n)$= x((n-m) mod N)。 比如对于长度为6的序列 x(n) = [1, 2, 3, 4, 5, 6]，如果要进行圆周移位2位，即将序列循环右移2位，那么得到的序列 x_2(n) 的数学表达式为： x_2(n) = x((n-2) mod 6) 具体地，x_2(0) = x(4) = 5，x_2(1) = x(5) = 6，x_2(2) = x(0) = 1，x_2(3) = x(1) = 2，x_2(4) = x(2) = 3，x_2(5) = x(3) = 4，因此序列x(n)经过2位圆周移位后的序列为 x_2(n) = [5, 6, 1, 2, 3, 4]。 无限长单位冲激响应（IIR）滤波器的结构是阶跃型的。 线性移不变系统的性质有线性性质、时不变性质和分配律。 线性性质：系统对输入信号的响应具有线性性质，即满足叠加原理和比例原理。 时不变性质：系统的性质不随时间而改变，即对于相同的输入信号，其响应在不同的时间点是相同的。 可积性质：系统对有限信号和幂级数信号均可积。 此外，线性性质还满足加法分配律和数乘分配律，即对于系统和输入信号的加法或数乘运算，这些运算可以分别在系统和输入信号上进行，即满足加法分配律和数乘分配律。 用 DFT 近似分析模拟信号的频谱时，可能出现的问题有频谱泄露、混叠和截断误差。 频谱泄露：当信号的频率不是精确地等于DFT的频率分辨率时，DFT会将该频率的能量泄漏到邻近的频率上，从而导致频谱泄露。 混叠：当信号的频率高于采样率的一半时，DFT无法正确地还原原始频谱，并产生混叠现象，即高频部分的能量被误认为是低频部分的能量。 截断误差：DFT要求信号的长度必须是2的幂次方，因此在对非2的幂次方长度的信号进行DFT时，会对信号进行补零或者截断，从而引入截断误差。 无限长单位冲激响应滤波器的基本结构有FIR型，IIR型和混合型。 两个有限长序列 $x_1(n)$，0≤n≤33 和 $x_2(n)$，0≤n≤36，做线性卷积后结果的长度是 ，若对这两个序列做 64 点圆周卷积，则圆周卷积结果中 n= 至 为线性卷积结果。 DFT 是利用$W_{N}^{nk}$的 、 和 三个固有特性来实现 FFT 快速运算的。 IIR 数字滤波器设计指标一般由 、 、 和 等四项组成。 一稳定 LTI 系统的 IIR 数 字滤 波 器有 、 和 三 种 设计 方 法 ，其 结构有 、 、 和 等多种结构。 FIR 滤波器的窗函数设计法中，滤波器的过渡带宽度与窗函数的 有关，阻带衰减与窗函数的 有关。 序列x n n ( ) sin(3 / 5)  =的周期为 。 线性时不变系统的性质有 律、 律、 律。 对4( ) ( ) x n R n = 的 Z 变换为 ，其收敛域为 。 抽样序列的 Z 变换与离散傅里叶变换 DFT 的关系为 。 设计一个巴特沃斯低通滤波器， 要求通带截止频率 $f_p=6 kHz$，通带最大衰减 $a_p=3 dB$， 阻带截止频率 $f_s=12kHz$， 阻带最小衰减 $a_s=25 dB$。求出滤波器归一化系统函数 G(p)以及实际滤波器的 $H_a(s)$。 求出归一化的巴特沃斯低通滤波器的单位根位置：$f_p=6 kHz$，$f_s=12kHz$，通带最大衰减 $a_p=3 dB$，阻带最小衰减 $a_s=25 dB$ 求出巴特沃斯滤波器的带宽 B：$B = f_s - f_p$ 求出巴特沃斯滤波器的归一化带宽：$ω₀ = 2 * π * f_p / f_s$ 求出巴特沃斯滤波器的单位根位置：$s = -(ln(a_s / a_p) / (2 * π * B / ω₀))^0.5$ 定义巴特沃斯滤波器的归一化系统函数：$G(p) = 1 / (1 + (p / ω₀)^2 + 2 * s * p / ω₀)$，p 是 Laplace 变量 实际的巴特沃斯低通滤波器的系统函数 $H_a(s)$ 可以通过以下方式转换：$H_a(s) = G(s / (2 * pi * fc)) * 2 * pi * f_c$，其中 fc 是滤波器的中心频率。","link":"/posts/4c6873b6.html"},{"title":"Go 语言数据库操作","text":"数据库连接建立和增删改查基本实现前面学院君给大家介绍了 Go 语言中的内存存储和文件存储，文件存储的好处是可以持久化数据，但是并不是 Web 应用数据存储的终极方案，因为这样存储起来的数据检索和管理起来非常麻烦，为此又诞生了数据库管理系统来处理数据的增删改查。数据库又可以划分为关系型数据库（RDBMS）和非关系型数据库（NoSQL），前者比如 MySQL、Oracle，后者比如 Redis、MongoDB，这里我们以当前最流行的开源关系型数据库 MySQL 为例进行介绍。 初始化数据库开始之前，我们先要连接到 MySQL 服务器初始化数据库和数据表。 注：如果你还没有在本地安装 MySQL 数据库，需要先进行安装，使用 Docker 启动或者去 MySQL 官网下载安装包安装均可，Mac 系统中还可以使用 Homebrew 进行安装，然后选择一个自己喜欢的 GUI 客户端，学院君本地使用的是 TablePlus。 做好上述准备工作连接到 MySQL 服务端之后，就可以创建一个名为 test_db 的数据库： 然后在这个数据库中创建一张名为 posts 的测试数据表用来存储文章信息： 12345678CREATE TABLE `posts` ( `id` bigint unsigned AUTO_INCREMENT, `title` varchar(100) DEFAULT NULL, `content` text, `author` varchar(30) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci; 建立数据库连接接下来，我们就可以在 Go 程序中编写代码建立与数据库的连接，然后对 posts 表进行增删改查操作了。 Go 语言并没有提供 MySQL 客户端扩展包的官方实现，只是提供了一个抽象的 database/sql 接口，只要第三方数据库客户端实现该接口声明的方法，用户就可以在不同的第三方数据库客户端扩展包实现之间进行切换，而不需要调整任何业务代码。 实现 database/sql 接口的 MySQL 第三方扩展包很多，比较流行的有 go-sql-driver/mysql 和 ORM 扩展包 go-gorm/gorm，我们先来看看如何通过 go-sql-driver/mysql 在 Go 程序中与 MySQL 数据库交互。 我们可以在测试代码 db.go 中编写一段 init 方法，在每次代码执行 main 入口函数之前先建立数据库连接： 1234567891011121314import ( &quot;database/sql&quot; _ &quot;github.com/go-sql-driver/mysql&quot;)var Db *sql.DB func init() { var err error Db, err = sql.Open(&quot;mysql&quot;, &quot;root:root@/test_db?charset=utf8mb4&amp;parseTime=true&quot;) if err != nil { panic(err) }} sql.DB 是一个用于操作数据库的结构体，维护的是一个数据库连接池。数据库连接通过 sql.Open 方法设置，该方法接收一个数据库驱动（这里是 mysql）和数据源名称字符串（按照位置填充即可，更多细节请参考该数据库包的官方文档）： 12[username[:password]@][protocol[(address)]]/dbname[?param1=value1&amp;...&amp;paramN=valueN] 注：如果 MySQL 服务器运行在本地，则 address 字段（IP + 端口号）留空。 成功后返回一个 sql.DB 指针，然后你就可以拿着这个指针操作数据库了。 需要注意的是 Open 方法并没有真正建立连接，也不回对传入的参数做任何验证，它只是负责初始化 sql.DB 结构体字段而已，数据库连接只有在后面真正需要的时候才会建立，是一个懒加载的过程。这样做的好处是提升应用性能，避免不必要的数据库连接开销。 另外，sql.DB 也不需要关闭，sql.DB 维护的是一个连接池，在我们的示例代码中定义了一个全局的 Db 变量来指向它，你还可以在创建 sql.DB 后将其传递给要操作数据库的方法。 接下来，我们来看下 Open 方法的参数，第一个参数是数据库驱动，要支持这个驱动需要调用 sql.Register 方法进行注册，由于我们使用了 go-sql-driver/mysql 这个第三方包，这一步是在 mysql 包的 init 方法中完成的（driver.go）： 1234func init() { sql.Register(&quot;mysql&quot;, &amp;MySQLDriver{})} 后面的驱动结构体需要实现 sql 包的 driver.Driver 接口。 当我们通过下面这段代码引入 mysql 包时： 12_ &quot;github.com/go-sql-driver/mysql&quot; 就会调用 mysql 包的 init 方法。 Go 官方没有提供任何数据库驱动包，只是在 sql.Driver 中声明了接口，第三方驱动包只要实现这些接口就好了。另外，我们在导入第三方包的时候，需要在前面加上短划线 _，这样做的好处是不会直接使用第三方包中的方法，只能使用官方 database/sql 中提供的方法，当第三方包升级或者需要调整数据库驱动时，不需要修改应用中的代码。 注：如果你对这一块接口与实现的细节不清楚，可以回顾 Go 入门教程中的面向对象编程部分。 增删改查示例代码数据库初始化完成并设置好连接配置之后，就可以在 Go 应用中与数据库进行交互了。我们将编写一段对文章表进行增删改查的示例代码来演示 Go 语言中的数据库操作。 注：以下所有示例代码都是在 db.go 中编写。 定义 Post 结构体首先我们需要定义一个表示文章表数据结构的结构体： 1234567type Post struct { Id int Title string Content string Author string} 创建新文章然后我们编写在数据库中创建文章记录的 Create 方法，其实就是在上述全局 Db 数据库连接上执行 SQL 插入语句而已，对应的示例代码如下： 123456789101112131415161718func (post *Post) Create() (err error) { sql := &quot;insert into posts (title, content, author) values (?, ?, ?)&quot; stmt, err := Db.Prepare(sql) if err != nil { panic(err) } defer stmt.Close() res, err := stmt.Exec(post.Title, post.Content, post.Author) if err != nil { panic(err) } postId, _ := res.LastInsertId() post.Id = int(postId) return} 注：这里我们使用了预处理语句，以避免 SQL 注入攻击，如果你有 PHP 或者其他语言数据库编程基础的话，应该很容易看懂这些代码。 实际上，我们还可以通过 stmt.QueryRow(post.Title, post.Content, post.Author) 来执行插入操作，效果是一样的，也可以直接通过 Db.Exec 执行插入操作： 12res, err := Db.Exec(sql, post.Title, post.Content, post.Author) 获取单篇文章创建完文章后，可以通过 Db.QueryRow 执行一条 SQL 查询语句查询单条记录并将结果映射到 Post 结构体中。 1234567func GetPost(id int) (post Post, err error) { post = Post{} err = Db.QueryRow(&quot;select id, title, content, author from posts where id = ?&quot;, id). Scan(&amp;post.Id, &amp;post.Title, &amp;post.Content, &amp;post.Author) return} 获取文章列表我们可以使用 sql.DB 提供的 Query 方法来查询多条文章记录： 1234567891011121314151617func Posts(limit int) (posts []Post, err error) { rows, err := Db.Query(&quot;select id, title, content, author from posts limit ?&quot;, limit) if err != nil { panic(err) } defer rows.Close() for rows.Next() { post := Post{} err = rows.Scan(&amp;post.Id, &amp;post.Title, &amp;post.Content, &amp;post.Author) if err != nil { panic(err) } posts = append(posts, post) } return} 该方法返回的是 sql.Rows 接口，它是一个迭代器，你可以通过循环调用其 Next 方法返回其中的每个 sql.Row 对象，直到 sql.Rows 中的记录值为空（此时返回 io.EOF）。 在循环体中，我们将每个 sql.Row 对象映射到 Post 对象，再将这个 Post 对象添加到 posts 切片中。 其实对于单条记录，也可以使用类似的方式实现，毕竟单条记录查询是 SELECT 查询的特例： 12345678910111213141516func GetPost(id int) (post Post, err error) { rows, err := Db.Query(&quot;select id, title, content, author from posts where id = ? limit 1&quot;, id) if err != nil { panic(err) } defer rows.Close() for rows.Next() { post = Post{} err = rows.Scan(&amp;post.Id, &amp;post.Title, &amp;post.Content, &amp;post.Author) if err != nil { panic(err) } } return} 当然，前面的 Db.Query 也可以调整为预处理语句实现，只是更繁琐一些： 1234567891011stmt, err := Db.Prepare(&quot;select id, title, content, author from posts limit ?&quot;)if err != nil { panic(err)}defer stmt.Close()rows, err := stmt.Query(limit)if err != nil { panic(err)}... // 后续其他操作代码 更新文章对于已存在的文章记录，可以通过执行 SQL 更新语句进行修改： 123456789func (post *Post) Update() (err error) { stmt, err := Db.Prepare(&quot;update posts set title = ?, content = ?, author = ? where id = ?&quot;) if err != nil { return } stmt.Exec(post.Title, post.Content, post.Author, post.Id) return} 当然，也可以通过 stmt.QueryRow 以及 Db.Exec 这两种方式来处理上述操作，使用 Db.Exec 方法更简洁： 123456func (post *Post) Update() (err error) { _, err = Db.Exec(&quot;update posts set title = ?, content = ?, author = ? where id = ?&quot;, post.Title, post.Content, post.Author, post.Id) return} Db.Exec 方法返回的是 sql.Result 接口，该接口支持以下两个方法： 我们不需要处理这个 Result 对象，所以通过 _ 将其忽略。 删除文章删除操作和更新操作类似，只是将 UPDATE 语句调整为 DELETE 语句而已： 123456789func (post *Post) Delete() (err error) { stmt, err := Db.Prepare(&quot;delete from posts where id = ?&quot;) if err != nil { return } stmt.Exec(post.Id) return} 当然上述操作可以通过 stmt.QueryRow 或 Db.Exec 方法来实现： 12345func (post *Post) Delete() (err error) { _, err = Db.Exec(&quot;delete from posts where id = ?&quot;, post.Id) return} 整体测试最后，我们在 db.go 中编写入口函数 main 测试一下上述数据库增删改查操作是否可以正常运行： 1234567891011121314151617181920212223func main() { post := Post{Title: &quot;Go 语言数据库操作&quot;, Content: &quot;基于第三方 go-sql-driver/mysql 包实现 MySQL 数据库增删改查&quot;, Author: &quot;学院君&quot;} // 创建记录 post.Create() fmt.Println(post) // 获取单条记录 dbPost, _ := GetPost(post.Id) fmt.Println(dbPost) // 更新记录 dbPost.Title = &quot;Golang 数据库操作&quot; dbPost.Update() // 获取文章列表 posts, _ := Posts(1) fmt.Println(posts) // 删除记录 dbPost.Delete()} 注：运行前，记得通过 Go Module 下载 go-sql-driver/mysql 依赖。 在终端运行 db.go，输出如下，表示这段数据库增删改查代码可以正常运行： 好了，关于数据库增删改查基本操作就简单介绍到这里，下篇教程，我们来看看如何在 MySQL 数据库中实现不同表之间的关联查询和更新。 完整代码【可直接运行】123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package mainimport ( &quot;database/sql&quot; &quot;fmt&quot; _ &quot;github.com/go-sql-driver/mysql&quot;)var Db *sql.DBtype Post struct { Id int Title string Content string Author string}func init() { var err error Db, err = sql.Open(&quot;mysql&quot;, &quot;root:password@/test_db?charset=utf8mb4&amp;parseTime=true&quot;) if err != nil { panic(err) }}func (post *Post) Create() (err error) { sql := &quot;insert into posts (title, content, author) values (?, ?, ?)&quot; stmt, err := Db.Prepare(sql) if err != nil { panic(err) } defer stmt.Close() res, err := stmt.Exec(post.Title, post.Content, post.Author) if err != nil { panic(err) } postId, _ := res.LastInsertId() post.Id = int(postId) return}func GetPost(id int) (post Post, err error) { post = Post{} err = Db.QueryRow(&quot;select id, title, content, author from posts where id = ?&quot;, id). Scan(&amp;post.Id, &amp;post.Title, &amp;post.Content, &amp;post.Author) return}func Posts(limit int) (posts []Post, err error) { rows, err := Db.Query(&quot;select id, title, content, author from posts limit ?&quot;, limit) if err != nil { panic(err) } defer rows.Close() for rows.Next() { post := Post{} err = rows.Scan(&amp;post.Id, &amp;post.Title, &amp;post.Content, &amp;post.Author) if err != nil { panic(err) } posts = append(posts, post) } return}func (post *Post) Update() (err error) { stmt, err := Db.Prepare(&quot;update posts set title = ?, content = ?, author = ? where id = ?&quot;) if err != nil { return } stmt.Exec(post.Title, post.Content, post.Author, post.Id) return}func (post *Post) Delete() (err error) { stmt, err := Db.Prepare(&quot;delete from posts where id = ?&quot;) if err != nil { return } stmt.Exec(post.Id) return}func main() { post := Post{Title: &quot;Go 语言数据库操作&quot;, Content: &quot;基于第三方 go-sql-driver/mysql 包实现 MySQL 数据库增删改查&quot;, Author: &quot;学院君&quot;} // 创建记录 post.Create() fmt.Println(post) // 获取单条记录 dbPost, _ := GetPost(post.Id) fmt.Println(dbPost) // 更新记录 dbPost.Title = &quot;Golang 数据库操作&quot; dbPost.Update() // 获取文章列表 posts, _ := Posts(1) fmt.Println(posts) // 删除记录 dbPost.Delete()}","link":"/posts/2dba0c93.html"},{"title":"模式识别2023年2月春季期末考试复习资料","text":"选择题 Kn近邻元法较之Parzen窗法的优点是（ B ）A. 所需样本数较少 B. 稳定性较好 C. 分辨率较高 D. 连续性较好 基于最小错误率的贝叶斯决策规则可以采用不同的形式，下列不能表达其决策规则的是（ B ）A. 后验概率 B. 似然比 C. 类条件概率 D. 先验概率 下列关于贝叶斯网络错误的是（ C ）A. 预测和诊断需要己知网络结构和图中每个结点的条件概率表。B. 训练需要先建立网络结构，再计算每个结点的条件概率表。C. 贝叶斯网络的诊断是一个“自顶向下”的过程。D. 要使用训练好的贝叶斯网络，则网络中的所有先验概率和条件概率必须全部已知。 下面关于最大似然估计的说法中错误的是（ C ）A. 在最大似然估计中要求各个样本必须是独立抽取的。B. 最大似然估计是在已知概率密度函数的形式，但是参数未知的情况下，利用训练样本来估计未知参数。C. 在最大似然函数估计中，要估计的参数是一个不确定的量。D. 在最大似然估计中，可以使用对数形式的似然函数来进行估计。 Fisher线性判别函数的求解过程是将N维特征矢量投影在（ A ）进行。A. 一维空间 B. 二维空间C. 三维空间 D. N-1维空间 两类样本中离分类面最近的样本到分类面的距离称作( D )A. 最小距离 B. 分类距离 C. 决策距离 D. 分类间隔 下面哪项不属于模式识别的主要方法的是（ A ）A. 基于数据的方法和基于特征的方法B. 基于知识的方法和基于数据的方法C. 基于统计的方法和基于数据的方法D. 基于知识的方法和基于统计的方法 在统计模式分类问题中，当先验概率未知时，除了N-P判决，还可以使用（ B ）A. 最小损失准则B. 最小最大损失准则C. 最小误判概率准则D. 最大误判概率准则 下列描述有监督学习错误的是（ C ）A. 有标签B. 核心是分类C. 所有数据都相互独立分布D. 分类原因不透明 填空题 CART算法是基于基尼系数的大小选择最有辨别力的特征对数据进行划分。 统计决策基本原理：根据各类特征的概率模型来估算后验概率,通过比较后验概率进行决策。 决策树算法能够处理离散型和连续型特征，并能把特征的信息和规则结合起来。 判断题 特征选择是新的每一个特征是原有特征的一个函数。（ 错误 ） 准则不同，所得到的线性判别函数也不同。（ 正确 ） 在模式识别中，获取的特征数量越多越有利于分类。（ 错误 ） 简答题 简述模式识别原理。 模式识别是一种对未知样本的特征进行分析、识别和归类的科学方法。它的基本原理是利用样本特征的数学方法对样本数据进行特征提取和分析，建立分类模型，再根据这些分类模型对新的数据进行分类。 在实际应用中，模式识别通常分为三个步骤：预处理、特征提取和分类。预处理步骤主要是对原始数据进行处理，以提高后续处理的准确性。特征提取步骤是从预处理后的数据中提取出具有代表性的特征。最后，分类算法将特征数据输入模型进行比较，并根据比较结果进行分类。 朴素贝叶斯平滑处理。 朴素贝叶斯平滑处理是一种解决零概率问题的方法。 零概率问题是指在计算实例的概率时，如果某个属性或特征在训练集中没有出现过，会导致整个实例的概率为零。这是不合理的，不能因为一个事件没有观察到就认为该事件的概率是零。 平滑处理的基本思想是给每个属性或特征一个非零的初始计数，以避免出现零概率。 常用的平滑处理方法有拉普拉斯平滑和加法平滑。 Boosting的基本思想和优缺点？ Boosting的基本思想是： 在每一轮迭代中，根据上一轮的分类结果，给训练数据赋予不同的权重 使得误分类的样本权重增大，正确分类的样本权重减小 然后用加权的数据集训练下一个弱分类器 最后将所有的弱分类器按照一定的规则结合起来得到最终的分类器。 Boosting的优点有： 可以有效地降低偏差和方差，提高泛化能力 可以处理高维数据和非线性问题 可以自动进行特征选择和剪枝 可以与其他机器学习算法结合使用 Boosting的缺点有： 训练过程比较耗时 容易过拟合 需要调整多个参数 使用Boosting的模式识别方法有决策树分类、支持向量机分类、K近邻分类和神经网络分类。 各个分类器的优缺点比较分析。 k近邻：优点是简单、无需训练、对异常值不敏感；缺点是计算量大、空间复杂度高、需要选择合适的k值。 决策树：优点是易于理解和实现、能够处理多值属性和缺失值；缺点是容易过拟合、不稳定、忽略属性之间的相关性。 支持向量机：优点是能够处理非线性问题、具有良好的泛化能力；缺点是对参数敏感、计算复杂度高、难以解释。 神经网络：优点是能够学习复杂的非线性函数、适用于大规模数据；缺点是训练时间长、容易陷入局部最优解、难以理解内部机制 。 信息增益和信息熵的特性。 信息熵是非负的，当且仅当随机变量只有一个取值时，信息熵为零。 信息增益也是非负的，当且仅当条件和随机变量相互独立时，信息增益为零。 信息熵满足对称性、凸性和可加性。 信息增益满足对称性、非凸性和非可加性。 k近邻思想。 k近邻思想是一种基于相似度的分类和回归方法，它的基本思想是从训练集中找到和输入样本最相似的k个样本，然后根据这k个样本的类别或数值来预测输入样本的输出。 估计概率密度的基本方法。 估计概率密度的基本方法有两大类：参数估计和非参数估计。 参数估计是指已知概率密度函数的形式，但其中部分或全部参数未知，通过样本来估计这些参数的值。常用的参数估计方法有最大似然估计和贝叶斯估计。 非参数估计是指不假设概率密度函数的形式，而是直接根据样本来构造概率密度函数。常用的非参数估计方法有直方图法、核密度法、k近邻法等。","link":"/posts/710b856a.html"},{"title":"Go 开发并发的Web应用","text":"【实战】开发一个自增整数生成器在 Python 和 PhP 中,使用 yield 关键字来让—个函数成为生成器。在Go语言中，则可以使用通道来创建生成器。下面是一个创建自增整数生成器的示例：直到主线向通道索要数据，才添加数据到通道。 1234567891011121314151617181920212223242526package mainimport &quot;fmt&quot;//生成自增的整数func IntegerGenerator() chan int{ var ch chan int = make(chan int) // 开启 goroutine go func() { for i := 0; ; i++ { ch &lt;- i // 直到通道索要数据，才把i添加进信道 } }() return ch}func main() { generator := IntegerGenerator() for i:=0; i &lt; 100; i++ { //生成100个自增的整数 fmt.Println(&lt;-generator) }} 【实战】开发一个并发的消息发送器在大流量的 Web 应用中，消息数据往往比较大。这时应该将消息部署成为一个独立的服务，消息服务只负责返回某个用户的新的消息提醒。开发一个并发的消息发送器的示例如下： 123456789101112131415161718192021222324252627package mainimport &quot;fmt&quot;func SendNotification(user string) chan string { //......此处省略查询数据库获取新消息。 //声明一个通道来保存消息 notifications := make(chan string, 500) // 开启一个通道 go func() { //将消息放入通道 notifications &lt;- fmt.Sprintf(&quot;Hi %s, welcome to our site!&quot;, user) }() return notifications}func main() { barry := SendNotification(&quot;barry&quot;) // 获取barry的消息 shirdon := SendNotification(&quot;shirdon&quot;) // 获取shirdon的消息 // 获取消息的返回 fmt.Println(&lt;-barry) fmt.Println(&lt;-shirdon)}","link":"/posts/14e55b49.html"},{"title":"Go语言经典库使用分析| 高性能可扩展 HTTP 路由 httprouter","text":"https://www.zhihu.com/search?type=content&amp;q=httprouter https://github.com/julienschmidt/httprouter https://zhuanlan.zhihu.com/p/83120695 http://c.biancheng.net/view/66.html https://learnku.com/articles/27591 https://juejin.cn/post/6844904115131121677","link":"/posts/34d309a9.html"},{"title":"牛客网Go语言专项训练刷题85题","text":"对于以下代码，正确的是:a=1212345678910111213141516package main import &quot;fmt&quot; func main() { a := 12 { a := 13 _ = a // make compiler happy } fmt.Println(a) } 本题考察对作用域的了解，在作用域内的 a 在作用域外失效，所以输出 12。要注意 { } 代码块里是 a := 13 是在一个新的作用域内重新声明了一个 a 变量，与外部的 a 变量无关。在 {} 代码块中的变量a为局部变量，只在 {} 中有效！ 比较大众的的说法是go语言的指针不支持运算，所以无法对指针进行自增或自减运算，也不可以对指针进行下标运算。Go语言究竟能不能对指下标运算呢？ 123456789101112package main import &quot;fmt&quot; func main() { a := 1024 m := map[string]*int{ &quot;A&quot;:&amp;a } // invalid operation: cannot take address of m[&quot;A&quot;] (map index expression of type *int) fmt.Println(&amp;m[&quot;A&quot;]) }","link":"/posts/75e8d596.html"},{"title":"Go语言公共组件开发之错误码标准化","text":"错误码标准化是为了在软件开发过程中，统一管理和处理错误信息，从而提高开发效率和用户体验。以下是一些错误码标准化的实践建议： 统一错误码的格式和定义：错误码应该按照一定的格式进行定义，例如使用数字、字母或组合作为错误码的标识符，同时应该定义每个错误码对应的错误信息和建议解决方法。 按照错误的类型进行分类：错误码应该按照错误的类型进行分类，例如网络错误、用户输入错误、服务器错误等。 定义错误码的范围：错误码的范围应该明确定义，避免重复和冲突，同时也有利于后续的扩展和管理。 统一错误码的命名和管理：错误码应该统一命名，并进行分类和管理，例如可以使用文档或数据库来管理错误码。 错误码应该具有可读性和可理解性：错误码的定义应该具有可读性和可理解性，方便开发人员和用户快速识别错误类型和解决方案。 错误码应该具有可追溯性：错误码的定义应该具有可追溯性，方便开发人员定位和解决问题。 错误码应该具有可扩展性：错误码的定义应该具有可扩展性，方便后续新增错误类型和解决方案。 通过对错误码进行标准化的管理和定义，可以提高软件开发过程中的错误处理效率和用户体验，同时也方便开发人员和用户理解和解决错误问题。 以下是一个使用Go语言实现简单错误码标准化的示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( &quot;fmt&quot;)// 定义错误码常量const ( ErrorInvalidInput = 1001 ErrorUnauthorized = 1002 ErrorNotFound = 1003 ErrorInternalServer = 1004 ErrorConnectionRefused = 1005)// 定义错误信息映射var ErrorMessage = map[int]string{ ErrorInvalidInput: &quot;Invalid input, please check your input parameters&quot;, ErrorUnauthorized: &quot;Unauthorized, please login first&quot;, ErrorNotFound: &quot;The resource you requested could not be found&quot;, ErrorInternalServer: &quot;Internal server error, please try again later&quot;, ErrorConnectionRefused: &quot;Connection refused, please try again later&quot;,}// 定义错误码类型type ErrorCode int// 实现错误码的字符串化方法func (e ErrorCode) String() string { if msg, ok := ErrorMessage[int(e)]; ok { return fmt.Sprintf(&quot;%d: %s&quot;, e, msg) } return fmt.Sprintf(&quot;%d: Unknown error&quot;, e)}// 模拟返回错误码的函数func DoSomething() error { // 模拟网络错误 return ErrorCode(ErrorConnectionRefused)}func main() { err := DoSomething() if err != nil { fmt.Println(err) }} 在这个示例代码中，我们首先定义了一些常量，代表不同类型的错误。接着，我们定义了一个名为ErrorMessage的映射，将错误码和错误信息一一对应起来。然后，我们定义了一个类型ErrorCode，用来表示错误码。在ErrorCode类型中，我们实现了String()方法，用来将错误码转换成字符串表示，同时将错误信息和错误码一起返回。最后，我们定义了一个模拟返回错误码的函数DoSomething()，该函数返回一个ErrorCode类型的错误。在main()函数中，我们调用了DoSomething()函数，当返回值为非空时，将错误码打印出来。这个示例代码中，我们使用常量来定义错误码，使用映射将错误码和错误信息一一对应起来，同时实现了错误码的字符串化方法，方便打印和输出错误信息。这是一种简单的错误码标准化实践。在实际开发中，可能需要更复杂的错误处理机制，但是这个示例代码可以作为一个起点，帮助了解如何在Go语言中实现错误码标准化。 除此之外，可以使用Go语言的包管理机制，将不同的功能组织到不同的包中，并在需要使用的地方进行引用。以下是一个使用包管理机制的示例代码：errors.go 12345678910package errors// 定义错误码常量const ( ErrorInvalidInput = 1001 ErrorUnauthorized = 1002 ErrorNotFound = 1003 ErrorInternalServer = 1004 ErrorConnectionRefused = 1005) error_string.go 1234567891011121314151617181920212223package errorsimport &quot;fmt&quot;// 定义错误信息映射var ErrorMessage = map[int]string{ ErrorInvalidInput: &quot;Invalid input, please check your input parameters&quot;, ErrorUnauthorized: &quot;Unauthorized, please login first&quot;, ErrorNotFound: &quot;The resource you requested could not be found&quot;, ErrorInternalServer: &quot;Internal server error, please try again later&quot;, ErrorConnectionRefused: &quot;Connection refused, please try again later&quot;,}// 定义错误码类型type ErrorCode int// 实现错误码的字符串化方法func (e ErrorCode) String() string { if msg, ok := ErrorMessage[int(e)]; ok { return fmt.Sprintf(&quot;%d: %s&quot;, e, msg) } return fmt.Sprintf(&quot;%d: Unknown error&quot;, e)} 然后，我们在一个新的文件中引入这两个包，并使用其中的定义，如下所示： 123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;your-package-name/errors&quot;)// 模拟返回错误码的函数func DoSomething() error { // 模拟网络错误 return errors.ErrorCode(errors.ErrorConnectionRefused)}func main() { err := DoSomething() if err != nil { fmt.Println(err) }} 在这个示例代码中，我们首先将错误码常量和错误信息映射分别定义在了errors.go和error_string.go两个文件中，并将它们都放在了一个名为errors的包中。然后，在main.go文件中，我们使用import语句引入了errors包，并使用其中定义的ErrorCode类型和DoSomething()函数，来演示如何在不同的文件中相互引用。 使用Go语言的包管理机制，能够方便地将不同的功能组织到不同的包中，并在需要使用的地方进行引用。这种方式有利于提高代码的可读性、可维护性和可重用性。 我们还能继续优化使用Go语言的包管理机制，可以将一个包分成多个文件，以便更好地组织和管理代码。以下是一个使用包管理机制、将错误码和错误信息映射分别定义在不同文件中的示例代码：errors.go 1234567891011package errors// 定义错误码常量const ( ErrorInvalidInput = 1001 ErrorUnauthorized = 1002 ErrorNotFound = 1003 ErrorInternalServer = 1004 ErrorDatabase = 1005) messages.go 12345678910package errors// 定义错误信息映射var ErrorMessage = map[int]string{ ErrorInvalidInput: &quot;Invalid input, please check your input parameters&quot;, ErrorUnauthorized: &quot;Unauthorized, please login first&quot;, ErrorNotFound: &quot;The resource you requested could not be found&quot;, ErrorInternalServer: &quot;Internal server error, please try again later&quot;, ErrorDatabase: &quot;Database error, please try again later&quot;,} errors.go 1234567891011121314package errorsimport &quot;fmt&quot;// 定义错误码类型type ErrorCode int// 实现错误码的字符串化方法func (e ErrorCode) String() string { if msg, ok := ErrorMessage[int(e)]; ok { return fmt.Sprintf(&quot;%d: %s&quot;, e, msg) } return fmt.Sprintf(&quot;%d: Unknown error&quot;, e)} 然后，在调用包中的函数时，可以像这样使用： 1234567891011121314151617181920package mainimport ( &quot;fmt&quot; &quot;your-package-name/errors&quot;)func main() { err := someFunction() if err != nil { fmt.Println(err) }}func someFunction() error { // 模拟一个错误 return errors.ErrorCode(errors.ErrorInvalidInput)} 在这个示例代码中，我们将错误码常量、错误信息映射和错误码类型定义分别放在了三个不同的文件中，然后在errors.go文件中使用import语句引入了fmt包，以便实现ErrorCode类型的字符串化方法。 使用Go语言的包管理机制，能够方便地将一个包分成多个文件，并在不同的文件中相互引用，这种方式有利于提高代码的可读性、可维护性和可重用性。 能再分开一点吗？分成更多的文件 当然可以。使用Go语言的包管理机制，可以将一个包分成多个文件，以便更好地组织和管理代码。以下是一个使用包管理机制、将错误码和错误信息映射分别定义在不同文件中的示例代码： errors.go 1234567891011package errors// 定义错误码常量const ( ErrorInvalidInput = 1001 ErrorUnauthorized = 1002 ErrorNotFound = 1003 ErrorInternalServer = 1004 ErrorDatabase = 1005) messages.go 1234567891011package errors// 定义错误信息映射var ErrorMessage = map[int]string{ ErrorInvalidInput: &quot;Invalid input, please check your input parameters&quot;, ErrorUnauthorized: &quot;Unauthorized, please login first&quot;, ErrorNotFound: &quot;The resource you requested could not be found&quot;, ErrorInternalServer: &quot;Internal server error, please try again later&quot;, ErrorDatabase: &quot;Database error, please try again later&quot;,} errors.go 1234567891011121314package errorsimport &quot;fmt&quot;// 定义错误码类型type ErrorCode int// 实现错误码的字符串化方法func (e ErrorCode) String() string { if msg, ok := ErrorMessage[int(e)]; ok { return fmt.Sprintf(&quot;%d: %s&quot;, e, msg) } return fmt.Sprintf(&quot;%d: Unknown error&quot;, e)} 然后，在调用包中的函数时，可以像这样使用： 1234567891011121314151617181920package mainimport ( &quot;fmt&quot; &quot;your-package-name/errors&quot;)func main() { err := someFunction() if err != nil { fmt.Println(err) }}func someFunction() error { // 模拟一个错误 return errors.ErrorCode(errors.ErrorInvalidInput)} 在这个示例代码中，我们将错误码常量、错误信息映射和错误码类型定义分别放在了三个不同的文件中，然后在errors.go文件中使用import语句引入了fmt包，以便实现ErrorCode类型的字符串化方法。 使用Go语言的包管理机制，能够方便地将一个包分成多个文件，并在不同的文件中相互引用，这种方式有利于提高代码的可读性、可维护性和可重用性。 能放入五个文件里面吗？当然可以。根据你的需求和实际情况，你可以将一个包分成多个文件，将相关的代码组织在一起，使得代码更加清晰和易于维护。下面是一个示例，将错误码和错误信息映射、错误码类型定义、以及字符串化方法分别放在不同的文件中： 非常抱歉，这是我的失误。在我之前的回答中，有两个文件名为errors.go的文件。这样会导致文件名冲突，无法通过编译。请忽略我之前的回答，以下是一个更合理的示例： errors.go 1234567891011goCopy codepackage errors// 定义错误码常量const ( ErrorInvalidInput = 1001 ErrorUnauthorized = 1002 ErrorNotFound = 1003 ErrorInternalServer = 1004 ErrorDatabase = 1005) messages.go 1234567891011goCopy codepackage errors// 定义错误信息映射var ErrorMessage = map[int]string{ ErrorInvalidInput: &quot;Invalid input, please check your input parameters&quot;, ErrorUnauthorized: &quot;Unauthorized, please login first&quot;, ErrorNotFound: &quot;The resource you requested could not be found&quot;, ErrorInternalServer: &quot;Internal server error, please try again later&quot;, ErrorDatabase: &quot;Database error, please try again later&quot;,} types.go 12345goCopy codepackage errors// 定义错误码类型type ErrorCode int format.go 123456789101112goCopy codepackage errorsimport &quot;fmt&quot;// 实现错误码的字符串化方法func (e ErrorCode) String() string { if msg, ok := ErrorMessage[int(e)]; ok { return fmt.Sprintf(&quot;%d: %s&quot;, e, msg) } return fmt.Sprintf(&quot;%d: Unknown error&quot;, e)} util.go 1234567goCopy codepackage errors// 将错误码转换为错误类型func ErrorCode(errCode int) error { return ErrorCode(errCode)} 在这个示例代码中，我们将错误码常量、错误信息映射、错误码类型定义、以及字符串化方法分别放在了不同的文件中，并在util.go文件中添加了一个ErrorCode()函数，将错误码转换为错误类型。这样可以使得代码更加清晰和易于维护。 format.go能实现哪些效果，写出具体的例子在之前的示例代码中，我们定义了一个format.go文件，其中实现了一个String()方法。String()方法用于将ErrorCode类型转换为字符串，以便打印或返回给调用方。 下面是一个具体的示例： 12345678910111213141516171819goCopy codepackage mainimport ( &quot;fmt&quot; &quot;example.com/errors&quot;)func main() { // 创建一个 ErrorCode 类型的变量 errCode := errors.ErrorCode(errors.ErrorNotFound) // 使用 fmt 包的 %v 格式化字符输出错误信息 fmt.Printf(&quot;%v\\n&quot;, errCode) // 使用 fmt 包的 %s 格式化字符输出错误信息 fmt.Printf(&quot;%s\\n&quot;, errCode)} 这段代码中，我们使用errors.ErrorCode()函数将错误码转换为ErrorCode类型的变量，并将其赋值给errCode变量。然后，我们使用fmt.Printf()函数，使用%v和%s格式化字符输出错误信息。在输出中，我们会看到类似于以下内容的字符串： 123makefileCopy code1003: The resource you requested could not be found1003: The resource you requested could not be found 其中，1003是错误码，The resource you requested could not be found是与之对应的错误信息。这是通过String()方法实现的。 util.go没看懂，讲解一下在之前的示例代码中，我们定义了一个util.go文件，其中实现了一个ErrorCode()函数。ErrorCode()函数用于将错误码转换为ErrorCode类型的变量，并返回该变量。实现的目的是使得在创建一个新的错误变量时，可以直接使用错误码常量而不必手动转换成ErrorCode类型。 下面是一个具体的示例： 123456789101112131415161718192021goCopy codepackage mainimport ( &quot;fmt&quot; &quot;example.com/errors&quot;)func main() { // 创建一个 ErrorCode 类型的变量 err := errors.ErrorCode(errors.ErrorInvalidInput) // 输出错误变量的值 fmt.Println(err) // 检查错误码是否相等 if err == errors.ErrorCode(errors.ErrorInvalidInput) { fmt.Println(&quot;The error code is equal to ErrorInvalidInput&quot;) }} 在这个示例代码中，我们使用errors.ErrorCode()函数创建了一个ErrorCode类型的变量，并将其赋值给err变量。ErrorCode()函数的内部实现是将输入的错误码转换成ErrorCode类型并返回。 在第二个例子中，我们使用if语句检查err变量的值是否等于errors.ErrorCode(errors.ErrorInvalidInput)。如果相等，则输出字符串&quot;The error code is equal to ErrorInvalidInput&quot;。这样，我们就可以方便地使用错误码常量来创建和比较错误变量了。","link":"/posts/369e8346.html"},{"title":"HTTP应用总结","text":"blogService源码 viper WIKI 李文周Goweb Go语言配置管理神器——Viper中文教程 编写公共组件刚想正式的开始编码，你会突然发现，怎么什么配套组件都没有，写起来一点都不顺手，没法形成闭环。 实际上在我们每个公司的项目中，都会有一类组件，我们常称其为基础组件，又或是公共组件，它们是不带强业务属性的，串联着整个应用程序，一般由负责基建或第一批搭建的该项目的同事进行梳理和编写，如果没有这类组件，谁都写一套，是非常糟糕的，并且这个应用程序是无法形成闭环的。 因此在这一章节我们将完成一个 Web 应用中最常用到的一些基础组件，保证应用程序的标准化，一共分为如下五个板块： 错误码标准化在应用程序的运行中，我们常常需要与客户端进行交互，而交互分别是两点，一个是正确响应下的结果集返回，另外一个是错误响应的错误码和消息体返回，用于告诉客户端，这一次请求发生了什么事，因为什么原因失败了。而在错误码的处理上，又延伸出一个新的问题，那就是错误码的标准化处理，不提前预判，将会造成比较大的麻烦，如下： 在上图中，我们可以看到客户端分别调用了三个不同的服务端，三个服务端 A、B、C，它们的响应结果的模式都不一样…如果不做任何挣扎的话，那客户端就需要知道它调用的是哪个服务，然后每一个服务写一种错误码处理规则，非常麻烦，那如果后面继续添加新的服务端，如果又不一样，那岂不是适配的更加多了？ 至少在大的层面来讲，我们要尽可能的保证每个项目前后端的交互语言规则是一致的，因此在一个新项目搭建之初，其中重要的一项预备工作，那就是标准化我们的错误码格式，保证客户端是“理解”我们的错误码规则，不需要每次都写一套新的。 公共错误码我们需要在在项目目录下的 pkg/errcode 目录新建 common_code.go 文件，用于预定义项目中的一些公共错误码，便于引导和规范大家的使用，如下： 1234567891011var ( Success = NewError(0, &quot;成功&quot;) ServerError = NewError(10000000, &quot;服务内部错误&quot;) InvalidParams = NewError(10000001, &quot;入参错误&quot;) NotFound = NewError(10000002, &quot;找不到&quot;) UnauthorizedAuthNotExist = NewError(10000003, &quot;鉴权失败，找不到对应的 AppKey 和 AppSecret&quot;) UnauthorizedTokenError = NewError(10000004, &quot;鉴权失败，Token 错误&quot;) UnauthorizedTokenTimeout = NewError(10000005, &quot;鉴权失败，Token 超时&quot;) UnauthorizedTokenGenerate = NewError(10000006, &quot;鉴权失败，Token 生成失败&quot;) TooManyRequests = NewError(10000007, &quot;请求过多&quot;)) 错误处理接下来我们在项目目录下的 pkg/errcode 目录新建 errcode.go 文件，编写常用的一些错误处理公共方法，标准化我们的错误输出，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768type Error struct { code int `json:&quot;code&quot;` msg string `json:&quot;msg&quot;` details []string `json:&quot;details&quot;`}var codes = map[int]string{}func NewError(code int, msg string) *Error { if _, ok := codes[code]; ok { panic(fmt.Sprintf(&quot;错误码 %d 已经存在，请更换一个&quot;, code)) } codes[code] = msg return &amp;Error{code: code, msg: msg}}func (e *Error) Error() string { return fmt.Sprintf(&quot;错误码：%d, 错误信息：%s&quot;, e.Code(), e.Msg())}func (e *Error) Code() int { return e.code}func (e *Error) Msg() string { return e.msg}func (e *Error) Msgf(args []interface{}) string { return fmt.Sprintf(e.msg, args...)}func (e *Error) Details() []string { return e.details}func (e *Error) WithDetails(details ...string) *Error { newError := *e newError.details = []string{} for _, d := range details { newError.details = append(newError.details, d) } return &amp;newError}func (e *Error) StatusCode() int { switch e.Code() { case Success.Code(): return http.StatusOK case ServerError.Code(): return http.StatusInternalServerError case InvalidParams.Code(): return http.StatusBadRequest case UnauthorizedAuthNotExist.Code(): fallthrough case UnauthorizedTokenError.Code(): fallthrough case UnauthorizedTokenGenerate.Code(): fallthrough case UnauthorizedTokenTimeout.Code(): return http.StatusUnauthorized case TooManyRequests.Code(): return http.StatusTooManyRequests } return http.StatusInternalServerError} 在错误码方法的编写中，我们声明了 Error 结构体用于表示错误的响应结果，并利用 codes 作为全局错误码的存储载体，便于查看当前注册情况，并在调用 NewError 创建新的 Error 实例的同时进行排重的校验。 另外相对特殊的是 StatusCode 方法，它主要用于针对一些特定错误码进行状态码的转换，因为不同的内部错误码在 HTTP 状态码中都代表着不同的意义，我们需要将其区分开来，便于客户端以及监控/报警等系统的识别和监听。 配置管理在应用程序的运行生命周期中，最直接的关系之一就是应用的配置读取和更新。它的一举一动都有可能影响应用程序的改变，其分别包含如下行为：","link":"/posts/5dcc809a.html"},{"title":"Go语言高级编程(Advanced Go Programming)","text":"Go语言高级编程(Advanced Go Programming) GPM GC xorm 1go env -w GOPROXY=https://goproxy.cn,direct https://github.com/JIeJaitt/video-server https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/04.1.md","link":"/posts/43af5e27.html"},{"title":"Go语言垃圾回收","text":"Go语言中使用的垃圾回收使用的是标记清扫算法。进行垃圾回收时会 stoptheworld。不过在Go语言 1.3 版本中，实现了精确的垃圾回收和并行的垃圾回收，大大地提高了垃圾回收的速度，进行垃圾回收时系统并不会长时间卡住。 标记清扫算法标记清扫算法是一个很基础的垃圾回收算法，该算法中有一个标记初始的 root 区域，以及一个受控堆区。root 区域主要是程序运行到当前时刻的栈和全局数据区域。在受控堆区中，很多数据是程序以后不需要用到的，这类数据就可以被当作垃圾回收了。 判断一个对象是否为垃圾，就是看从 root 区域的对象是否有直接或间接的引用到这个对象。如果没有任何对象引用到它，则说明它没有被使用，因此可以安全地当作垃圾回收掉。 标记清扫算法分为两阶段，分别是标记阶段和清扫阶段。 标记阶段，从 root 区域出发，扫描所有 root 区域的对象直接或间接引用到的对象，将这些对上全部加上标记； 清扫阶段，扫描整个堆区，对所有无标记的对象进行回收。 位图标记和内存布局参考资料 http://c.biancheng.net/view/vip_7363.html","link":"/posts/aa9b68a9.html"},{"title":"Cobra","text":"解释一下在main函数中调用cmd.ShioriCmd().Execute()函数来在这个程序中，cmd.ShioriCmd()返回一个cobra.Command对象，该对象包含了所有的命令行工具命令。 执行Execute()方法后，cobra.Command对象会解析命令行参数，并调用相应的函数来处理命令。具体来说，它会查找用户输入的命令，在cobra.Command对象中寻找与该命令名称相对应的函数，然后调用该函数来处理命令。 cmd.ShioriCmd().Execute()函数的返回值是一个error类型的值，如果命令执行成功，则返回nil，否则返回一个非nil的error对象。 在这里，如果执行命令时出现了错误，程序会使用logrus库输出错误日志，并以非0的退出码结束运行。 Execute()方法一般在项目里面有什么作用的？Execute()方法是cobra.Command对象的一个方法，用于解析命令行参数，并执行相应的命令。在一个命令行工具应用程序中，通常会使用cobra.Command对象来定义各种命令，然后通过调用Execute()方法来运行这些命令。 具体来说，Execute()方法会解析命令行参数，并根据参数调用相应的函数来处理命令。如果解析参数时出现错误，或者找不到与输入的命令名称相匹配的函数，则会返回一个error对象。否则，Execute()方法会返回nil。 在实际项目中，Execute()方法通常被用来启动应用程序的主逻辑。在命令行工具应用程序中，Execute()方法会根据用户输入的命令来调用不同的函数，从而实现各种不同的功能。例如，一个命令行工具应用程序可以包含多个命令，如build、run、test等，用户可以通过输入不同的命令来执行相应的功能，而Execute()方法则会根据输入的命令来调用不同的函数来处理相应的功能。 总之，Execute()方法是cobra.Command对象的核心方法，它实现了命令行工具应用程序的核心逻辑，是命令行工具应用程序的必要组成部分。 能写一个例子给我看看吗？好的，下面是一个简单的命令行工具示例程序，其中使用了cobra库进行命令行参数解析和命令执行： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport ( &quot;fmt&quot; &quot;os&quot; &quot;github.com/spf13/cobra&quot;)func main() { // 创建一个名为 rootCmd 的 cobra 命令 rootCmd := &amp;cobra.Command{ // 命令的使用说明 Use: &quot;demo&quot;, // 命令的简短说明 Short: &quot;A simple demo command line tool&quot;, // 命令的详细说明 Long: &quot;A simple demo command line tool to demonstrate how to use cobra library&quot;, // 命令的执行函数 Run: func(cmd *cobra.Command, args []string) { // 执行函数中的代码，输出一句话 fmt.Println(&quot;Hello, this is demo tool&quot;) }, } // Add subcommand &quot;add&quot; addCmd := &amp;cobra.Command{ Use: &quot;add [number1] [number2]&quot;, Short: &quot;Add two numbers&quot;, Long: &quot;Add two numbers and print the result&quot;, Args: cobra.ExactArgs(2), Run: func(cmd *cobra.Command, args []string) { num1 := args[0] num2 := args[1] fmt.Printf(&quot;%s + %s = %d\\n&quot;, num1, num2, sum(num1, num2)) }, } rootCmd.AddCommand(addCmd) // Add subcommand &quot;version&quot; versionCmd := &amp;cobra.Command{ Use: &quot;version&quot;, Short: &quot;Print the version number of demo tool&quot;, Run: func(cmd *cobra.Command, args []string) { fmt.Println(&quot;Version 1.0.0&quot;) }, } rootCmd.AddCommand(versionCmd) // Execute the root command if err := rootCmd.Execute(); err != nil { fmt.Println(err) os.Exit(1) }}func sum(num1 string, num2 string) int { return len(num1) + len(num2)} 在这个示例程序中，我们定义了一个根命令demo，并添加了两个子命令add和version。其中，add命令可以接受两个参数并将其相加，version命令用于输出程序的版本号。 当用户在命令行中输入demo add 2 3时，程序会执行addCmd命令，将参数2和3相加并输出结果。 当用户在命令行中输入demo version时，程序会执行versionCmd命令，输出程序的版本号。 当用户在命令行中输入不正确的参数时，程序会输出错误信息并退出。 这个示例程序演示了如何使用cobra库来实现一个简单的命令行工具，其中Execute()方法被用来解析命令行参数并执行相应的命令。 当用户在命令行中输入demo add 2 3时，程序会输出如下结果： 12# ./demo add 2 32 + 3 = 2 这个结果的计算过程是通过sum()函数实现的，它将两个字符串的长度相加并返回。因此，对于输入的参数2和3，分别计算它们的长度为1和1，相加后得到2，所以输出结果为2 + 3 = 2。 当用户在命令行中输入demo version时，程序会输出如下结果： 12# ./demo versionVersion 1.0.0 这个结果是由versionCmd命令的Run()函数实现的，它直接输出了程序的版本号。","link":"/posts/d6db6725.html"},{"title":"rand 随机数生成方法研究草稿","text":"package rand 实现了用于加解密的更安全的随机数生成器。 1import &quot;crypto/rand&quot; Variables1var Reader io.Reader Reader是一个全局、共享的密码用强随机数生成器。在Unix类型系统中，会从/dev/urandom读取；而Windows中会调用CryptGenRandom API。 12345678910111213141516171819202122package main import( &quot;fmt&quot; &quot;encoding/base64&quot; &quot;crypto/rand&quot; &quot;io&quot;)//sessionId函数用来生成一个session ID，即session的唯一标识符func sessionId() string { b := make([]byte, 32) //ReadFull从rand.Reader精确地读取len(b)字节数据填充进b //rand.Reader是一个全局、共享的密码用强随机数生成器 if _, err := io.ReadFull(rand.Reader, b); err != nil { return &quot;&quot; } fmt.Println(b) //[62 186 123 16 209 19 130 218 146 136 171 211 12 233 45 99 80 200 59 20 56 254 170 110 59 147 223 177 48 136 220 142] return base64.URLEncoding.EncodeToString(b)//将生成的随机数b编码后返回字符串,该值则作为session ID}func main() { fmt.Println(sessionId()) //Prp7ENETgtqSiKvTDOktY1DIOxQ4_qpuO5PfsTCI3I4=} func Int1func Int(rand io.Reader, max *big.Int) (n *big.Int, err error) 返回一个在[0, max)区间服从均匀分布的随机值，如果max&lt;=0则会panic。 1234567891011121314151617181920package main import( &quot;fmt&quot; &quot;crypto/rand&quot; &quot;math/big&quot;)func main() { //从128开始，这样就能够将(max.BitLen() % 8) == 0的情况包含在里面 for n := 128; n &lt; 140; n++ { b := new(big.Int).SetInt64(int64(n)) //将new(big.Int)设为int64(n)并返回new(big.Int) fmt.Printf(&quot;max Int is : %v\\n&quot;, b) i, err := rand.Int(rand.Reader, b) if err != nil { fmt.Printf(&quot;Can't generate random value: %v, %v&quot;, i, err) } fmt.Printf(&quot;rand Int is : %v\\n&quot;, i) }} 12345678910111213141516171819202122232425bogon:~ user$ go run testGo.go max Int is : 128rand Int is : 25max Int is : 129rand Int is : 117max Int is : 130rand Int is : 85max Int is : 131rand Int is : 62max Int is : 132rand Int is : 27max Int is : 133rand Int is : 120max Int is : 134rand Int is : 10max Int is : 135rand Int is : 27max Int is : 136rand Int is : 11max Int is : 137rand Int is : 119max Int is : 138rand Int is : 35max Int is : 139rand Int is : 83 func Prime1func Prime(rand io.Reader, bits int) (p *big.Int, err error) 返回一个具有指定字位数的数字，该数字具有很高可能性是质数。如果从rand读取时出错，或者bits&lt;2会返回错误。 12345678910111213141516171819202122package main import( &quot;fmt&quot; &quot;crypto/rand&quot;)func main() { for n := 2; n &lt; 10; n++ { p, err := rand.Prime(rand.Reader, n) //n代表位数，比如3为2位，127为7位 if err != nil { fmt.Printf(&quot;Can't generate %d-bit prime: %v&quot;, n, err) } if p.BitLen() != n { //返回p的绝对值的字位数，0的字位数为0 fmt.Printf(&quot;%v is not %d-bit&quot;, p, n) } if !p.ProbablyPrime(32) { //对p进行32次Miller-Rabin质数检测。如果方法返回真则p是质数的几率为1-(1/4)**32；否则p不是质数 fmt.Printf(&quot;%v is not prime&quot;, p) } fmt.Println(p) }} 123456789bogon:~ user$ go run testGo.go 37133153109223439 如果位数小于2的话，会报错： 123456789101112131415package main import( &quot;fmt&quot; &quot;crypto/rand&quot; &quot;log&quot;)func main() { p, err := rand.Prime(rand.Reader, 1) //n代表位数，比如3为2位，127为7位 if err != nil { log.Fatal(err) } fmt.Println(p)} 123bogon:~ user$ go run testGo.go 2019/02/23 12:31:37 crypto/rand: prime size must be at least 2-bitexit status 1 func Read1func Read(b []byte) (n int, err error) 本函数是一个使用io.ReadFull调用Reader.Read的辅助性函数。当且仅当err == nil时，返回值n == len(b)。 123456789101112131415161718192021222324c := 10 b := make([]byte, c) // func Read(b []byte) (n int, err error)// 生成 b 切片大小的随机数_, err := rand.Read(b) if err != nil { fmt.Println(&quot;error:&quot;, err) return } // func Equal(a []byte, b []byte) bool// Equal 返回 a 和 b 是否具有相同的长度并包含相同的字节// 也就断判断两个切片的内容是否完全相同。// 一个 nil 参数相当于一个空切片（empty slice）。fmt.Println(bytes.Equal([]byte(&quot;Go&quot;), []byte(&quot;Go&quot;)))fmt.Println(bytes.Equal([]byte(&quot;Go&quot;), []byte(&quot;C++&quot;)))// Output:// true// false// 切片现在应该包含随机字节（random bytes），而不仅仅是零。// Output:// falsefmt.Println(bytes.Equal(b, make([]byte, c))) 因为本函数是一个使用io.ReadFull调用Reader.Read的辅助性函数，所以最上面的那个生成session ID的例子等价于： 123456789101112131415161718192021package main import( &quot;fmt&quot; &quot;encoding/base64&quot; &quot;crypto/rand&quot;)//sessionId函数用来生成一个session ID，即session的唯一标识符func sessionId() string { b := make([]byte, 32) //rand.Reader是一个全局、共享的密码用强随机数生成器 n, err := rand.Read(b); if err != nil { return &quot;&quot; } fmt.Println(b[:n]) //[154 94 244 2 147 96 148 6 13 27 3 52 231 127 160 159 40 47 84 116 79 87 160 217 185 216 47 143 101 107 219 178] return base64.URLEncoding.EncodeToString(b)//将生成的随机数b编码后返回字符串,该值则作为session ID}func main() { fmt.Println(sessionId()) //ml70ApNglAYNGwM053-gnygvVHRPV6DZudgvj2Vr27I=} Read Function12345// Read 是一个辅助函数，它使用 io.ReadFull 调用 Reader.Read。// 返回时，n == len(b) 当且仅当 err == nil。func Read(b []byte) (n int, err error) { return io.ReadFull(Reader, b)} 简单来说，它读出的数据，并不一定是指定长度的。 ReadFull Function12345678910// ReadFull 将 r 中的 len(buf) 个字节准确地读入 buf。// 它返回复制的字节数，如果读取的字节数较少，则返回错误。// 仅当没有读取字节时，错误才是 EOF。// 如果在读取一些但不是所有字节后发生 EOF，// ReadFull 返回 ErrUnexpectedEOF。// 返回时，n == len(buf) 当且仅当 err == nil。// 如果 r 返回一个读取了至少 len(buf) 个字节的错误，则删除该错误。func ReadFull(r Reader, buf []byte) (n int, err error) { return ReadAtLeast(r, buf, len(buf))} 意思是读取正好len(buf)长度的字节。如果字节数不是指定长度，则返回错误信息和正确的字节数。当没有字节能被读时，返回EOF错误。如果读了一些，但是没读完产生EOF错误时，返回ErrUnexpectedEOF错误。 Reader interface12345678910111213141516171819202122// Reader 是封装了基本 Read 方法的接口。//// Read 最多将 len(p) 个字节读入 p。// 它返回读取的字节数 (0 &lt;= n &lt;= len(p)) 和遇到的任何错误。// 即使 Read 返回 n &lt; len(p)，它也可能在调用期间使用所有 p 作为暂存空间。// 如果某些数据可用但不是 len(p) 字节，Read 通常会返回可用的数据，而不是等待更多。//// 当Read成功读取n&gt;0个字节后遇到错误或文件结束条件时，返回读取的字节数。// 它可能会从同一次调用中返回非零（non-nil）错误，或者从后续调用中返回错误（并且 n == 0）。// 这种一般情况的一个例子是，在输入流末尾返回非零字节数的 Reader 可能会返回 err == EOF 或 err == nil。// 下一次读 Read 应该返回 0，EOF。//// 在考虑错误 err 之前，调用者应始终处理返回的 n &gt; 0 字节。// 这样做可以正确处理读取一些字节后发生的 I/O 错误以及允许的 EOF 行为。//// 不鼓励 Read 的实现返回零字节计数并返回 nil 错误，除非 len(p) == 0。// 调用者应该将返回的 0 和 nil 视为没有发生任何事情；特别是它不表示EOF。//// 实现不能保留 p。type Reader interface { Read(p []byte) (n int, err error)}","link":"/posts/57e7820e.html"},{"title":"经典库httprouter源码阅读","text":"简介官方：https://github.com/julienschmidt/httprouter 文档：https://godoc.org/github.com/julienschmidt/httprouter HttpRouter is a lightweight high performance HTTP request router (also called multiplexer or just mux for short) for Go. In contrast to the default mux of Go’s net/http package, this router supports variables in the routing pattern and matches against the request method. It also scales better. The router is optimized for high performance and a small memory footprint. It scales well even with very long paths and a large number of routes. A compressing dynamic trie (radix tree) structure is used for efficient matching. 简单描述，httprouter是一个golang实现的路由组件。httprouter使用一个前缀树来维护映射的父子关系，通过前缀树快速路由。同时其里面的HttpRouter结构体实现了golang的net.http.server的Handler接口，可以作为httpHandle发布。golang以性能出名的gin使用的也就是httprouter来做路由处理。 在go web开发中，很多时候会选用一款web框架，随着项目功能增加，接口也越来越多，一款好的路由框架能很方便的帮助我们管理与维护繁多的接口地址。 特性 基于基数树实现的高性能路由框架 仅支持精确匹配 不必关心 URL 结尾的斜线 路径自动校正，例如在 url 路径当中有../,//的时候 可以在 URL 当中设置参数，例如/user/:id 零内存分配 不存在服务器崩溃，可以通过设置panic handler使服务器从 panic 当中恢复 适合 API 构建 httprouter解读 核心思想 与defaultServeMux的实现区别在于什么？采取特殊的数据结构作路由。 defaultServeMux的实现采用什么样的数据结构？ httprouter的实现采用什么样的数据结构？ router的架构图是怎样的，与server.go有何异同 一些http相关的细节 其他细节 细读源码 Router的 paramsPool？sync.Pool需要看看 done 修复重定向是代码大头，得细细解读重定向相关的协议内容 这部分先跳过吧，细节太多了 http包的server.go里面req的context里面包含了params怎么取消的。done “server.serve =&gt; conn.serve ==&gt;defer cancleCtx/ w.cancelCtx() ” 因此， 最要紧的就是看tree.go里面定义的数据结构。最好找图帮助理解 tree addRoute方法为切入口 初次阅读有几个不明白的地方，还需要回顾router.go 具体的路由规则要烂熟，由此解读node的几个类型 priority/wildchild/indices的意思和作用 test文件的测试有没有没覆盖到的情况？ node 的结构123456789type node struct { path string indices string wildChild bool nType nodeType priority uint32 children []*node handle Handle} 依赖1require github.com/julienschmidt/httprouter latest 使用Demo12345678910111213141516package httpRouterDemoimport ( &quot;net/http&quot; &quot;github.com/julienschmidt/httprouter&quot;)func Index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) { w.Write([]byte(&quot;hello world&quot;))}func main() { router := httprouter.New() router.GET(&quot;/&quot;, Index) http.ListenAndServe(&quot;:80&quot;, router)} 123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; &quot;github.com/julienschmidt/httprouter&quot; &quot;net/http&quot; &quot;log&quot;)func Index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) { fmt.Fprint(w, &quot;Welcome!\\n&quot;)}func Hello(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { fmt.Fprintf(w, &quot;hello, %s!\\n&quot;, ps.ByName(&quot;name&quot;))}func main() { router := httprouter.New() router.GET(&quot;/&quot;, Index) router.GET(&quot;/hello/:name&quot;, Hello) log.Fatal(http.ListenAndServe(&quot;:8080&quot;, router))} 和http包的ServeMux用法其实很类似。上面定义了两个httprouter中的handle，类似于http包中的http.HandlerFunc类型，具体的对应关系后文会解释，只要认为它是handler，是处理对应请求的就行了。然后使用New()方法创建了实例，并使用GET()方法为两个模式注册了对应的handler。 需要注意的是，第二个模式”/hello/:name”，它可以用来做命名匹配，类似于正则表达式的命名捕获分组。后面会详细解释用法。 httprouter用法说明1234567891011121314151617181920212223Variablesfunc CleanPath(p string) stringtype Handletype Paramtype Params func ParamsFromContext(ctx context.Context) Params func (ps Params) ByName(name string) stringtype Router func New() *Router func (r *Router) DELETE(path string, handle Handle) func (r *Router) GET(path string, handle Handle) func (r *Router) HEAD(path string, handle Handle) func (r *Router) Handle(method, path string, handle Handle) func (r *Router) Handler(method, path string, handler http.Handler) func (r *Router) HandlerFunc(method, path string, handler http.HandlerFunc) func (r *Router) Lookup(method, path string) (Handle, Params, bool) func (r *Router) OPTIONS(path string, handle Handle) func (r *Router) PATCH(path string, handle Handle) func (r *Router) POST(path string, handle Handle) func (r *Router) PUT(path string, handle Handle) func (r *Router) ServeFiles(path string, root http.FileSystem) func (r *Router) ServeHTTP(w http.ResponseWriter, req *http.Request) type Handlehttprouter中的Handle类似于http.HandlerFunc，只不过它支持第三个参数Params。 1234type Handle func(http.ResponseWriter, *http.Request, Params) Handle is a function that can be registered to a route to handle HTTP requests. Like http.HandlerFunc, but has a third parameter for the values of wildcards (variables). 例如前面示例中的Index()和Hello()都是Handle类型的实例。 1234567func Index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) { fmt.Fprint(w, &quot;Welcome!\\n&quot;)}func Hello(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { fmt.Fprintf(w, &quot;hello, %s!\\n&quot;, ps.ByName(&quot;name&quot;))} 注册handlerhttprouter.Router类型类似于http包中的ServeMux，它实现了http.Handler接口，所以它是一个http.Handler。它可以将请求分配给注册好的handler。 12type Router struct {}func (r *Router) ServeHTTP(w http.ResponseWriter, req *http.Request) 除此之外，Router提供了不少方法，用来指示如何为路径注册handler。 123func (r *Router) Handle(method, path string, handle Handle)func (r *Router) Handler(method, path string, handler http.Handler)func (r *Router) HandlerFunc(method, path string, handler http.HandlerFunc) httprouter.Handle()用于为路径注册指定的Handle，而httprouter.Handle对应于http.HandlerFunc，所以是直接将Handle类型的函数绑定到指定路径上。同时，它还可以指定http方法：GET, POST, HEAD, PUT, PATCH, DELETE, OPTIONS。 这些方法还有对应的各自缩写： 1234567func (r *Router) DELETE(path string, handle Handle)func (r *Router) GET(path string, handle Handle)func (r *Router) HEAD(path string, handle Handle)func (r *Router) OPTIONS(path string, handle Handle)func (r *Router) PATCH(path string, handle Handle)func (r *Router) POST(path string, handle Handle)func (r *Router) PUT(path string, handle Handle) 例如，Get()等价于route.Handle(“GET”, path, handle)。 例如上面的示例中，为两个路径注册了各自的httprouter.Handle函数。 123router := httprouter.New()router.GET(&quot;/&quot;, Index)router.GET(&quot;/hello/:name&quot;, Hello) Handler()方法是直接为指定http方法和路径注册http.Handler；HandlerFunc()方法则是直接为指定http方法和路径注册http.HandlerFunc。 Param相关1234567891011type Param struct { Key string Value string}Param is a single URL parameter, consisting of a key and a value.type Params []ParamParams is a Param-slice, as returned by the router. The slice is ordered, the first URL parameter is also the first slice value. It is therefore safe to read values by the index.func (ps Params) ByName(name string) stringByName returns the value of the first Param which key matches the given name. If no matching Param is found, an empty string is returned. Param类型是key/value型的结构，每个分组捕获到的值都会保存为此类型。正如前面的示例中： 1router.GET(&quot;/hello/:name&quot;, Hello) 这里的:name就是key，当请求的URL路径为/hello/abc，则key对应的value为abc。也就是说保存了一个Param实例： 1234Param{ Key: &quot;name&quot;, Value: &quot;abc&quot;,} 更多的匹配用法稍后解释。 Params是Param的slice。也就是说，每个分组捕获到的key/value都存放在这个slice中。 ByName(str)方法可以根据Param的Key检索已经保存在slice中的Param的Value。正如示例中： 12345func Hello(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { fmt.Fprintf(w, &quot;hello, %s!\\n&quot;, ps.ByName(&quot;name&quot;))}router.GET(&quot;/hello/:name&quot;, Hello) 这里ByName(&quot;name&quot;)将检索保存在slice中，Key=”name”的Param，且返回这个Param中的Value。 由于Params是slice结构，除了ByName()方法可以检索key/value，通过slice的方法也可以直接检索： 12ps[0].Keyps[0].Value 路径匹配规则httprouter要为路径注册handler的适合，路径可以进行命名捕获。有两种命名捕获的方式： 123Syntax Type:name named parameter*name catch-all parameter 其中:name的捕获方式是匹配内容直到下一个斜线或者路径的结尾。例如要为如下路径注册handler: 1Path: /blog/:category/:post 当请求路径为： 1234/blog/go/request-routers match: category=&quot;go&quot;, post=&quot;request-routers&quot;/blog/go/request-routers/ no match, but the router would redirect/blog/go/ no match/blog/go/request-routers/comments no match *name的捕获方式是从指定位置开始(包含前缀”/“)匹配到结尾： 123456Path: /files/*filepath/files/ match: filepath=&quot;/&quot;/files/LICENSE match: filepath=&quot;/LICENSE&quot;/files/templates/article.html match: filepath=&quot;/templates/article.html&quot;/files no match, but the router would redirect 再解释下什么时候会进行重定向。在Router类型中，第一个字段控制尾随斜线的重定向操作： 1234type Router struct { RedirectTrailingSlash bool ...} 如果请求的URL路径包含或者不包含尾随斜线时，但在注册的路径上包含了或没有包含”/“的目标上定义了handler，但是会进行301重定向。简单地说，不管URL是否带尾随斜线，只要注册路径不存在，但在去掉尾随斜线或加上尾随斜线的路径上定义了handler，就会自动重定向。 例如注册路径为/foo，请求路径为/foo/，会重定向。 下面还有几种会重定向的情况： 12345678注册路径：/blog/:category/:post请求URL路径：/blog/go/request-routers/注册路径：/blog/:category请求URL路径：/blog/go注册路径：/files/*filepath请求URL路径：/files Lookup()1func (r *Router) Lookup(method, path string) (Handle, Params, bool) Lookup根据method+path检索对应的Handle，以及Params，并可以通过第三个返回值判断是否会进行重定向。 源码分析解决两个问题，就基本明白了这个路由框架 路由是是如何注册？如何保存的？ 当请求到来之后，路由是如何匹配，如何查找的？ 还是从一个Hello World讲起 1234567func main() { r := httprouter.New() r.GET(&quot;/:name&quot;, func(writer http.ResponseWriter, request *http.Request, params httprouter.Params) { fmt.Fprintf(writer, &quot;hello, %s!\\n&quot;, params.ByName(&quot;name&quot;)) }) http.ListenAndServe(&quot;:8080&quot;,r)} httprouter.New()初始化了一个 Router，下面直接看一下 Router 的结构 Router在 Router 的源码当中有十分详尽的注释，这里按照我个人的理解注释一下 1234567891011121314151617181920212223242526272829303132// Router实现了Http.Handler接口，用于注册分发路由type Router struct { // trees 是一个基数树集合，每一个HTTP方法对应一棵单独的路由树 // node是基数树的根节点 trees map[string]*node // 用于开启上文提到的自动处理URL尾部斜杆的特性 // 这个值为true时，如果/foo/没有被匹配到，会尝试匹配/foo RedirectTrailingSlash bool // 用于开启上文提到的路由校正的特性 // 这个值为true时，会对../和//这种路径进行校正 RedirectFixedPath bool // 这个值为true时，如果当前方法的路由没有被匹配到，会尝试匹配其他方法的路由， // 如果匹配到了则返回405，如果没有，就交给NotFound Handler处理 HandleMethodNotAllowed bool // 这个值为true时，将开启OPTIONS自动匹配，注意: 手动匹配优先级更高 HandleOPTIONS bool // 没有匹配到相应路由的时候会调用这个方法 // 如果没有注册这个方法会返回 NotFound NotFound http.Handler // 没有匹配到相应路由并且HandleMethodNotAllowed为true时会调用这个方法 MethodNotAllowed http.Handler // 用于从panic当中恢复 // 需要返回500错误，并且渲染相应的错误页面 PanicHandler func(http.ResponseWriter, *http.Request, interface{})} 初始化 Router 之后看看路由是如何保存并且注册的 路由是如何保存的?这里以官方 Readme 当中的例子说明：如果注册了以下路由 12345678r.GET(&quot;/&quot;, f1)r.GET(&quot;/search/&quot;, f2)r.GET(&quot;/support/&quot;, f3)r.GET(&quot;/blog/&quot;, f4)r.GET(&quot;/blog/:post/&quot;, f5)r.GET(&quot;/about_us/&quot;, f6)r.GET(&quot;/about_us/team/&quot;, f7)r.GET(&quot;/contact/&quot;, f8) 那么这些路由会如下方所示，以一颗树的形式保存，并且这些路由的公共前缀会被抽离并且变为上一层节点Priority 表示加上自身一共有多少个节点Path 表示路径Handle 表示路由注册的方法 1234567891011Priority Path Handle9 \\ *&lt;1&gt;3 ├s nil2 |├earch\\ *&lt;2&gt;1 |└upport\\ *&lt;3&gt;2 ├blog\\ *&lt;4&gt;1 | └:post nil1 | └\\ *&lt;5&gt;2 ├about-us\\ *&lt;6&gt;1 | └team\\ *&lt;7&gt;1 └contact\\ *&lt;8&gt; r.Handler.Get, r.Post等方法实质都是通过调用 r.Handle 实现的 123456789101112131415161718192021func (r *Router) Handle(method, path string, handle Handle) { // 路径注册必须从/开始，否则直接报错 if path[0] != '/' { panic(&quot;path must begin with '/' in path '&quot; + path + &quot;'&quot;) } // 路由树map不存在需要新建 if r.trees == nil { r.trees = make(map[string]*node) } // 获取当前方法所对应树的根节点，不存在则新建一个 root := r.trees[method] if root == nil { root = new(node) r.trees[method] = root } // 向路由树当中添加一条一条路由 root.addRoute(path, handle)} node路由是注册到一颗路由树当中的，先看看节点的源码，再来分析，是如何添加路由的 12345678910111213141516171819202122232425262728293031323334type node struct { // 当前节点的路径 path string // 是否为参数节点，参数节点用:name表示 wildChild bool // 当前节点类型， 一共有4种 // static: 静态节点，默认类型 // root: 根节点 // param: 其他节点 // catchAll: 带有*的节点，这里*的作用和正则当中的*一样 nType nodeType // 当前路径上最大参数的个数，不能超过255 maxParams uint8 // 代表分支的首字母 // 上面的例子，当前节点为s // 那么indices = eu // ├s nil // |├earch\\ *&lt;2&gt; // |└upport\\ *&lt;3&gt; indices string // 孩子节点 children []*node // 注册的路由 handle Handle // 权重，表示当前节点加上所有子节点的数目 priority uint32} 流程httprouter使用了前缀树来存储路由和其对应的处理函数。 httprouter为每个http方法均创建了一颗前缀树。 12345678910type node struct { path string // 路径 wildChild bool // 路径是否有通配符(:或*) nType nodeType // 节点类型，static（默认）,root,param,catchAll中的一种，对应值为0，1，2，3 maxParams uint8 // 当前节点及其子节点最大param数量 priority uint32 // 优先级 indices string // children的索引（孩子节点的第一个字母） children []*node // 孩子节点 handle Handle // 路由处理函数} 假如我们有下面这几个路径(GET方法)： 123456789/search//support/blog/:post//blog/:post/:name/files/*filepath 则创建的前缀树如下： 123456789101112/ ├─ blog/ │ └─ :post │ └─ / │ └─ :name ├─ files │ └─ &quot;&quot; │ └─ /*filepath └─ s ├─ earch └─ upport 插入代码为func (n *node) addRoute(path string, handle Handle)。 插入即为前缀树的插入操作，从根节点开始，查找树是否有相同前缀，对无共同前缀的部分进行插入操作，在这个操作中，原来的节点非共同前缀部分会作为子节点。 要注意的是，插入分为有参数（有:或*符号）和无参数两类 1.path为最大能利用的公共前缀，当为叶子节点时，则为除去路径前缀的剩余部分（无参数） 2.如果有参数的路径，在上一步会进行额外操作，把参数部分裂开作为一个单独节点。如:/blog/:name/:id/，即使其为叶子节点，会把:name和:id作为单独节点 3.如果有通配符(*)，则只能为最后一个节点。 查找查找代码func (n *node) getValue(path string) 查找时同样分为有参数和无参数两类 1.对于无参数的路径，直接根据node.path匹配，根据node.indices进入下一节点顺着树查找即可。 2.对于有参数的路径，区分参数（：符号）和通配符（*），拿到路径对应的参数，也比较简单。 总结 1.httprouter使用前缀树来复用空间 2.代码简洁易懂 3.支持路径传参和通配 4.有优先级，保证匹配的确定性 纵览New方法实际就是生成一个HttpRouter对象 接下来看看注册Get映射的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155func (r *Router) GET(path string, handle Handle) { r.Handle(http.MethodGet, path, handle)}func (r *Router) Handle(method, path string, handle Handle) { if len(path) &lt; 1 || path[0] != '/' { panic(&quot;path must begin with '/' in path '&quot; + path + &quot;'&quot;) } if r.trees == nil { r.trees = make(map[string]*node) } root := r.trees[method] if root == nil { root = new(node) r.trees[method] = root r.globalAllowed = r.allowed(&quot;*&quot;, &quot;&quot;) } root.addRoute(path, handle)}func (n *node) addRoute(path string, handle Handle) { fullPath := path n.priority++ numParams := countParams(path) // non-empty tree if len(n.path) &gt; 0 || len(n.children) &gt; 0 { walk: for { // Update maxParams of the current node if numParams &gt; n.maxParams { n.maxParams = numParams } //查询最长公共前缀 i := 0 max := min(len(path), len(n.path)) for i &lt; max &amp;&amp; path[i] == n.path[i] { i++ } // 出现部分前缀匹配，最极端情况/根路径 //创建一个以匹配部分为映射路径的空节点顶替当前匹配节点n，当前匹配节点n作为其子节点 if i &lt; len(n.path) { child := node{ path: n.path[i:], wildChild: n.wildChild, nType: static, indices: n.indices, children: n.children, handle: n.handle, priority: n.priority - 1, } // Update maxParams (max of all children) for i := range child.children { if child.children[i].maxParams &gt; child.maxParams { child.maxParams = child.children[i].maxParams } } n.children = []*node{&amp;child} // []byte for proper unicode char conversion, see #65 n.indices = string([]byte{n.path[i]}) n.path = path[:i] n.handle = nil n.wildChild = false } //到这里可以确认，n绝对可以成为注册映射的祖先节点 //找到最匹配的祖先节点作为自己的父节点 if i &lt; len(path) { path = path[i:] if n.wildChild { n = n.children[0] n.priority++ // Update maxParams of the child node if numParams &gt; n.maxParams { n.maxParams = numParams } numParams-- // Check if the wildcard matches if len(path) &gt;= len(n.path) &amp;&amp; n.path == path[:len(n.path)] &amp;&amp; // Adding a child to a catchAll is not possible n.nType != catchAll &amp;&amp; // Check for longer wildcard, e.g. :name and :names (len(n.path) &gt;= len(path) || path[len(n.path)] == '/') { continue walk } else { // Wildcard conflict var pathSeg string if n.nType == catchAll { pathSeg = path } else { pathSeg = strings.SplitN(path, &quot;/&quot;, 2)[0] } prefix := fullPath[:strings.Index(fullPath, pathSeg)] + n.path panic(&quot;'&quot; + pathSeg + &quot;' in new path '&quot; + fullPath + &quot;' conflicts with existing wildcard '&quot; + n.path + &quot;' in existing prefix '&quot; + prefix + &quot;'&quot;) } } c := path[0] // slash after param if n.nType == param &amp;&amp; c == '/' &amp;&amp; len(n.children) == 1 { n = n.children[0] n.priority++ continue walk } // Check if a child with the next path byte exists for i := 0; i &lt; len(n.indices); i++ { if c == n.indices[i] { i = n.incrementChildPrio(i) n = n.children[i] continue walk } } //插入子节点 // Otherwise insert it if c != ':' &amp;&amp; c != '*' { // []byte for proper unicode char conversion, see #65 n.indices += string([]byte{c}) child := &amp;node{ maxParams: numParams, } n.children = append(n.children, child) n.incrementChildPrio(len(n.indices) - 1) n = child } n.insertChild(numParams, path, fullPath, handle) return } else if i == len(path) { // Make node a (in-path) leaf if n.handle != nil { panic(&quot;a handle is already registered for path '&quot; + fullPath + &quot;'&quot;) } n.handle = handle } return } } else { //树是空的，直接作为root n.insertChild(numParams, path, fullPath, handle) n.nType = root }} 然后查看其处理请求的方式，也就是对前缀树进行查询 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200func (r *Router) ServeHTTP(w http.ResponseWriter, req *http.Request) { if r.PanicHandler != nil { defer r.recv(w, req) } path := req.URL.Path if root := r.trees[req.Method]; root != nil { //查询前缀树 if handle, ps, tsr := root.getValue(path); handle != nil { //handle请求 handle(w, req, ps) return } else if req.Method != http.MethodConnect &amp;&amp; path != &quot;/&quot; { code := 301 // Permanent redirect, request with GET method if req.Method != http.MethodGet { // Temporary redirect, request with same method // As of Go 1.3, Go does not support status code 308. code = 307 } if tsr &amp;&amp; r.RedirectTrailingSlash { if len(path) &gt; 1 &amp;&amp; path[len(path)-1] == '/' { req.URL.Path = path[:len(path)-1] } else { req.URL.Path = path + &quot;/&quot; } http.Redirect(w, req, req.URL.String(), code) return } // Try to fix the request path if r.RedirectFixedPath { fixedPath, found := root.findCaseInsensitivePath( CleanPath(path), r.RedirectTrailingSlash, ) if found { req.URL.Path = string(fixedPath) http.Redirect(w, req, req.URL.String(), code) return } } } } if req.Method == http.MethodOptions &amp;&amp; r.HandleOPTIONS { // Handle OPTIONS requests if allow := r.allowed(path, http.MethodOptions); allow != &quot;&quot; { w.Header().Set(&quot;Allow&quot;, allow) if r.GlobalOPTIONS != nil { r.GlobalOPTIONS.ServeHTTP(w, req) } return } } else if r.HandleMethodNotAllowed { // Handle 405 if allow := r.allowed(path, req.Method); allow != &quot;&quot; { w.Header().Set(&quot;Allow&quot;, allow) if r.MethodNotAllowed != nil { r.MethodNotAllowed.ServeHTTP(w, req) } else { http.Error(w, http.StatusText(http.StatusMethodNotAllowed), http.StatusMethodNotAllowed, ) } return } } // Handle 404 if r.NotFound != nil { r.NotFound.ServeHTTP(w, req) } else { http.NotFound(w, req) }}func (n *node) getValue(path string) (handle Handle, p Params, tsr bool) {walk: // outer loop for walking the tree for { //查询前缀树节点 if len(path) &gt; len(n.path) { if path[:len(n.path)] == n.path { path = path[len(n.path):] // If this node does not have a wildcard (param or catchAll) // child, we can just look up the next child node and continue // to walk down the tree if !n.wildChild { c := path[0] for i := 0; i &lt; len(n.indices); i++ { if c == n.indices[i] { n = n.children[i] continue walk } } // Nothing found. // We can recommend to redirect to the same URL without a // trailing slash if a leaf exists for that path. tsr = (path == &quot;/&quot; &amp;&amp; n.handle != nil) return } // handle wildcard child n = n.children[0] switch n.nType { case param: // find param end (either '/' or path end) end := 0 for end &lt; len(path) &amp;&amp; path[end] != '/' { end++ } // save param value if p == nil { // lazy allocation p = make(Params, 0, n.maxParams) } i := len(p) p = p[:i+1] // expand slice within preallocated capacity p[i].Key = n.path[1:] p[i].Value = path[:end] // we need to go deeper! if end &lt; len(path) { if len(n.children) &gt; 0 { path = path[end:] n = n.children[0] continue walk } // ... but we can't tsr = (len(path) == end+1) return } if handle = n.handle; handle != nil { return } else if len(n.children) == 1 { // No handle found. Check if a handle for this path + a // trailing slash exists for TSR recommendation n = n.children[0] tsr = (n.path == &quot;/&quot; &amp;&amp; n.handle != nil) } return case catchAll: // save param value if p == nil { // lazy allocation p = make(Params, 0, n.maxParams) } i := len(p) p = p[:i+1] // expand slice within preallocated capacity p[i].Key = n.path[2:] p[i].Value = path handle = n.handle return default: panic(&quot;invalid node type&quot;) } } } else if path == n.path { // We should have reached the node containing the handle. // Check if this node has a handle registered. if handle = n.handle; handle != nil { return } if path == &quot;/&quot; &amp;&amp; n.wildChild &amp;&amp; n.nType != root { tsr = true return } // No handle found. Check if a handle for this path + a // trailing slash exists for trailing slash recommendation for i := 0; i &lt; len(n.indices); i++ { if n.indices[i] == '/' { n = n.children[i] tsr = (len(n.path) == 1 &amp;&amp; n.handle != nil) || (n.nType == catchAll &amp;&amp; n.children[0].handle != nil) return } } return } // Nothing found. We can recommend to redirect to the same URL with an // extra trailing slash if a leaf exists for that path tsr = (path == &quot;/&quot;) || (len(n.path) == len(path)+1 &amp;&amp; n.path[len(path)] == '/' &amp;&amp; path == n.path[:len(n.path)-1] &amp;&amp; n.handle != nil) return }} 参考资料 Httprouter—用go实现的高性能路由器-腾讯云开发者社区-腾讯云 Httprouter介绍及源码阅读 httprouter源码阅读 - 掘金 Go Web：HttpRouter路由 - 骏马金龙 - 博客园 Gin框架的render包册单测文件有以下测试文件，你觉得还需要写什么测试文件 func TestRenderJSONfunc TestRenderJSONErrorfunc TestRenderIndentedJSONfunc TestRenderIndentedJSONPanicsfunc TestRenderSecureJSONfunc TestRenderSecureJSONFailfunc TestRenderJsonpJSONclass errorWriterfunc Writefunc TestRenderJsonpJSONErrorfunc TestRenderJsonpJSONError2func TestRenderJsonpJSONFailfunc TestRenderAsciiJSONfunc TestRenderAsciiJSONFailfunc TestRenderPureJSONtype xmlmapfunc MarshalXMLfun TestRenderYAMLclass failfunc MarshalYAMLfunc TestRenderYAMLFailfunc TestRenderTOMLfunc TestRenderTOMLFailfunc TestRenderProtoBuffunc TestRenderProtoBufFailfunc TestRenderXMLfunc TestRenderRedirectfunc TestRenderDatafunc TestRenderStringfunc TestRenderStringLenZerofunc TestRenderHTMLTemplatefunc TestRenderHTMLTemplateEmptyNamefunc TestRenderHTMLDebugFilesfunc TestRenderHTMLDebugGlobfunc TestRenderHTMLDebugPanicsfunc TestRenderReaderfunc TestRenderReaderNoContentLength","link":"/posts/2f2e68b6.html"}],"tags":[],"categories":[{"name":"期末考试","slug":"期末考试","link":"/categories/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"},{"name":"科班基础","slug":"科班基础","link":"/categories/%E7%A7%91%E7%8F%AD%E5%9F%BA%E7%A1%80/"},{"name":"算法竞赛","slug":"算法竞赛","link":"/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"},{"name":"项目实战","slug":"项目实战","link":"/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"pages":[{"title":"","text":"","link":"/about/index.html"}]}